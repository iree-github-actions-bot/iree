---
layout: default
permalink: Dialects/FlowDialect
title: "'flow' Dialect"
parent: Dialect Definitions
---

<!-- Autogenerated by mlir-tblgen; don't manually edit -->
# 'flow' Dialect
{: .no_toc }

A dialect designed to model execution data flow and partitioning.

The flow dialect is used to model regions of dense computation and the data
flow between them. MLIR value-semantic tensors are used as the primary data
type to allow SSA use-def to provide a bulk of the infrastructure required
to perform the computation partitioning and outlining.

The dialect is designed to ingest relatively high-level linear algebra via
XLA HLO ops (that also operate on the value-semantic tensor types) and
optionally MLIR standard ops for control flow and other actions. After
conversion of any higher-level ops that have special semantics in the flow
dialect, such as global variables, the rest are partitioned into regions
containing simple and compatible computations. Finally, outlining moves the
computations into executables and leaves only the execution flow encoded via
dispatch operations.

The primary unit of interest is a "dispatch region" containing compatible
computations that can be scheduled together efficiently (and safely).
"Compatible" here is specified as similarly shaped workloads that indicate
how many invocations a computation can be parallelized across when running
in a SPMD execution model. Though it depends on the particular runtime
backends this more concretely means things like the untiled workload
(or tiled workgroups) used in GPU dispatches or similar thread pool
executors.

After identification of the dispatchable regions a set of transformations
performs folding and simplification to reduce the total number of
dispatches. Heuristics are used in certain cases to more efficiently
schedule special ops (such as GEMM) and the design is amenable to profile-
guided analysis that can be added in the future.

The resulting outlined executable modules containing the dispatchable code
can be translated to one or more backends (such as SPIR-V for Vulkan, or
LLVM IR for running on the CPU, etc). The IR that is outlined is untouched
and in the input format (such as XLA HLO ops) allowing conversion using any
MLIR target that supports ingesting such input. A few special ops are used
to communicate statically available information such as the expected
workload size, shapes of inputs and outputs, etc.

1. TOC
{:toc}

## Type constraint definition

### dispatch.tensor
A placeholder for a dispatch region input/output operand. This can be used
to query the metadata about the tensor (such as its shape) as well as both
load and store from the backing tensor representation.

### dispatch.tensor
A placeholder for a dispatch region input operand. This can be used
to query the metadata about the tensor (such as its shape) as well as load
from the backing tensor representation.

### dispatch.tensor
A placeholder for a dispatch region output operand. This can be used
to query the metadata about the tensor (such as its shape) as well as store
to the backing tensor representation.

## Operation definition

### `flow.dispatch.entry` (::mlir::iree_compiler::IREE::Flow::DispatchEntryOp)

defines an executable entry point for dispatch operations

Specifies an exported function with an externally-visible alias. Multiple
exports can reference the same internal function.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`sym_name` | ::mlir::StringAttr | string attribute
`function_ref` | ::mlir::FlatSymbolRefAttr | flat symbol reference attribute
`signature` | ::mlir::TypeAttr | any type attribute
`workgroup_rank` | ::mlir::IntegerAttr | index attribute

### `flow.dispatch` (::mlir::iree_compiler::IREE::Flow::DispatchOp)

a dispatch of workgroups across an n-dimension grid


Syntax:

```
operation ::= `flow.dispatch` $entry_point `[` $workgroup_count `]` ``
              `(` $operands `)` attr-dict `:`
              custom<ShapedFunctionType>(ref($operands),
              type($operands), $operand_dims,
              type($results), $result_dims,
              $tied_operands)
```

Dispatches workgroups across an n-dimensional grid defined by the specified
workgroup count. The workgroup count may be dynamic and any dimension may be
set to 0 to neuter the dispatch (no workgroup will execute).

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`entry_point` | ::mlir::SymbolRefAttr | symbol reference attribute
`tied_operands` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`workgroup_count` | index
`operands` | any type
`operand_dims` | index
`result_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`results` | any type

### `flow.dispatch.region` (::mlir::iree_compiler::IREE::Flow::DispatchRegionOp)

partitioned region representing a dispatched workload

A closure that represents a functional dispatch unit. These perform
computations in a way that can be lowered to target executable formats such
as SPIR-V for execution.

Ops that are identified as "dispatchable" are grouped into dispatch regions
and compatible dispatch regions are folded together. What remains outside of
the dispatch regions is the glue required to schedule the work (commonly
referred to as "host" code, even if it doesn't run on an AP).

Dispatch regions are modeled using value semantics: it is assumed that all
arguments are read-only and that the dispatch regions themselves have no
side-effects.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`workload` | index
`args` | any type

#### Results:

| Result | Description |
| :----: | ----------- |
`results` | any type

### `flow.dispatch.shape` (::mlir::iree_compiler::IREE::Flow::DispatchShapeOp)

returns the shape of a dispatch region input/output tensor


Syntax:

```
operation ::= `flow.dispatch.shape` $source `:` type($source) `->` type($result) attr-dict
```

Queries the shape of an input or output tensor of a
`flow.dispatch.workgroups` region. The shape may have dynamic dimensions
that will be resolved to runtime values.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`source` | dispatch.tensor

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | Ranked shape type

### `flow.dispatch.tensor.load` (::mlir::iree_compiler::IREE::Flow::DispatchTensorLoadOp)

loads a tensor from a dispatch input placeholder


Syntax:

```
operation ::= `flow.dispatch.tensor.load` $source
              `,` `offsets` `=` custom<OperandsOrIntegersOffsetsOrStridesList>($offsets, $static_offsets)
              `,` `sizes` `=` custom<OperandsOrIntegersSizesList>($sizes, $static_sizes)
              `,` `strides` `=` custom<OperandsOrIntegersOffsetsOrStridesList>($strides, $static_strides)
              attr-dict `:` type($source) `->` type($result)
```

Loads an input tensor or subtensor from an input placeholder. As each
workgroup executes concurrently all workgroups will receive identical loaded
results of regions that may overlap.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`static_offsets` | ::mlir::ArrayAttr | 64-bit integer array attribute
`static_sizes` | ::mlir::ArrayAttr | 64-bit integer array attribute
`static_strides` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`source` | dispatch.tensor
`offsets` | index
`sizes` | index
`strides` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values

### `flow.dispatch.tensor.store` (::mlir::iree_compiler::IREE::Flow::DispatchTensorStoreOp)

stores a tensor into a dispatch output placeholder


Syntax:

```
operation ::= `flow.dispatch.tensor.store` $value `,` $target
              `,` `offsets` `=` custom<OperandsOrIntegersOffsetsOrStridesList>($offsets, $static_offsets)
              `,` `sizes` `=` custom<OperandsOrIntegersSizesList>($sizes, $static_sizes)
              `,` `strides` `=` custom<OperandsOrIntegersOffsetsOrStridesList>($strides, $static_strides)
              attr-dict `:` type($value) `->` type($target)
```

Stores a tensor or subtensor into an output tensor placeholder. As each
workgroup executes concurrently behavior is undefined if more than one
workgroup stores into overlapping regions of the full output tensor.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`static_offsets` | ::mlir::ArrayAttr | 64-bit integer array attribute
`static_sizes` | ::mlir::ArrayAttr | 64-bit integer array attribute
`static_strides` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`value` | ranked tensor of any type values
`target` | dispatch.tensor
`offsets` | index
`sizes` | index
`strides` | index

### `flow.dispatch.tie_shape` (::mlir::iree_compiler::IREE::Flow::DispatchTieShapeOp)

ties a runtime shape to a dispatch I/O argument


Syntax:

```
operation ::= `flow.dispatch.tie_shape` $operand `,` $shape attr-dict
              `:` `(` type($operand) `,` type($shape) `)` `->` type($result)
```

Metadata op used to tie a runtime-computed shape with dynamic dimensions to
a dispatch input/output argument. All uses of the argument should use the
pass-through result of this op to allow for SSA-based shape resolution.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`operand` | dispatch.tensor
`shape` | Ranked shape type

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | dispatch.tensor

### `flow.dispatch.workgroup.count` (::mlir::iree_compiler::IREE::Flow::DispatchWorkgroupCountOp)

returns the total workgroup count of the grid


Syntax:

```
operation ::= `flow.dispatch.workgroup.count` `[` $dimension `]` attr-dict `:` type($result)
```

The total number of workgroups along each dimension in the dispatch grid.

Corresponds to the `NumWorkgroups` SPIR-V built-in and the `gridDim` CUDA
built-in variable, only in the flow dialect the number of dimensions is not
restricted to 3 (XYZ).

```mlir
%x = flow.dispatch.workgroup.count[0] : index
%y = flow.dispatch.workgroup.count[1] : index
```

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`dimension` | ::mlir::IntegerAttr | index attribute

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | index

### `flow.dispatch.workgroup.id` (::mlir::iree_compiler::IREE::Flow::DispatchWorkgroupIDOp)

returns the index of the current workgroup in the grid


Syntax:

```
operation ::= `flow.dispatch.workgroup.id` `[` $dimension `]` attr-dict `:` type($result)
```

The global workgroup ID of the current workgroup in the range of
`[0, flow.dispatch.workgroup.count)` along each dimension.

Corresponds to the `WorkgroupId` SPIR-V built-in and the `blockIdx` CUDA
built-in variable, only in the flow dialect the number of dimensions is not
restricted to 3 (XYZ).

```mlir
%x = flow.dispatch.workgroup.id[0] : index
%y = flow.dispatch.workgroup.id[1] : index
```

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`dimension` | ::mlir::IntegerAttr | index attribute

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | index

### `flow.dispatch.workgroup.rank` (::mlir::iree_compiler::IREE::Flow::DispatchWorkgroupRankOp)

returns the rank of the workgroup dimensions


Syntax:

```
operation ::= `flow.dispatch.workgroup.rank` attr-dict `:` type($result)
```

The number of workgroup dimensions used during dispatch, bounding the
`flow.dispatch.workgroup.*` query functions.

```mlir
%rank = flow.dispatch.workgroup.rank : index
```

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | index

### `flow.dispatch.workgroup.size` (::mlir::iree_compiler::IREE::Flow::DispatchWorkgroupSizeOp)

returns the size of each workgroup in invocations


Syntax:

```
operation ::= `flow.dispatch.workgroup.size` `[` $dimension `]` attr-dict `:` type($result)
```

The number of local invocations within the current workgroup along each
dimension. Depending on backend this may map to the SIMT thread count or
inner loop nest parameters.

Workgroup sizes are not determined at the flow dialect level as they are
dependent on the target backend determined when lowering into the HAL. It's
still possible to use the symbolic workgroup size inside of dispatch
executables as a placeholder for the resolved value once in the HAL.

Corresponds to the `WorkgroupSize` SPIR-V built-in and the `blockDim` CUDA
built-in variable, only in the flow dialect the number of dimensions is not
restricted to 3 (XYZ).

```mlir
%x = flow.dispatch.workgroup.size[0] : index
%y = flow.dispatch.workgroup.size[1] : index
```

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`dimension` | ::mlir::IntegerAttr | index attribute

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | index

### `flow.dispatch.workgroups` (::mlir::iree_compiler::IREE::Flow::DispatchWorkgroupsOp)

a dispatch of workgroups across an n-dimension grid


Syntax:

```
operation ::= `flow.dispatch.workgroups` `[` $workgroup_count `]` ``
              `(` $operands `)` `:`
              custom<ShapedFunctionType>(ref($operands),
              type($operands), $operand_dims,
              type($results), $result_dims,
              $tied_operands)
              attr-dict-with-keyword
              `=` `\n` ` ` ` ` ` `
              custom<DispatchWorkgroupBody>(ref(type($operands)),
              ref(type($results)),
              $body)
```

Dispatches some number of workgroups across an n-dimensional grid. The
body region will be invoked for each workgroup with a unique
`flow.dispatch.workgroup.id` in the range of
`[0, flow.dispatch.workgroup.count)` (along each dimension).

From the outside the dispatch operation has value semantics: some tensors
(and optionally other primitive types) are consumed and one or more new
result tensors are produced. Inside each workgroup, however, the input and
output tensors are available for arbitrary loads and stores. In many cases
each workgroup will load some particular tile(s) from the input tensors and
store some particular tile(s) to the output tensors unique to that
workgroup. Though it's possible for multiple workgroups to load the same
regions of the input tensors behavior is undefined if multiple workgroups
store to the same regions of the output tensors.

Though the representation is similar to the GPU-style grid dispatch model
here we still have not yet allocated buffers, determined the target device
for execution, or even completed fully resolving shapes/types/etc. Because
of this it's important that the workgroup body use the
`flow.dispatch.workgroup.*` ops to query the workgroup ID/count/size instead
of hardcoding them to a particular set of values. Assume that any workgroup
dispatch may end up being specialized for several different target devices
and even several different variants for a particular target device
(differing workgroup sizes, etc).

Because of the general nature of the op in this dialect the workgroup count
provided to the `flow.dispatch.workgroups` op is in an abstract untiled
domain. Unlike when lowering to the HAL dialect the number of dimensions is
unbounded and does not yet have the workgroup size factored into it. As the
dispatch is lowered the workgroup count range will be converted into a 3D
XYZ grid space and divided up by the workgroup size chosen for particular
target devices.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`tied_operands` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`workgroup_count` | index
`operands` | any type
`operand_dims` | index
`result_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`results` | any type

### `flow.ex.stream.fragment` (::mlir::iree_compiler::IREE::Flow::ExStreamFragmentOp)

experimental op for defining formed stream regions


Syntax:

```
operation ::= `flow.ex.stream.fragment` `(` $operands `)` `:`
              custom<ShapedFunctionType>(ref($operands),
              type($operands), $operand_dims,
              type($results), $result_dims,
              $tied_operands)
              attr-dict-with-keyword
              `=` `\n` ` ` ` ` ` `
              custom<StreamFragmentBody>(ref(type($operands)),
              ref(type($results)),
              ref($tied_operands),
              $body)
```

Represents a region where all of the dispatches are meant to target the
same execution stream. This will be replaced with a segmented version in the
future that stitches the stream segments together.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`tied_operands` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`operands` | any type
`operand_dims` | index
`result_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`results` | any type

### `flow.executable_end` (::mlir::iree_compiler::IREE::Flow::ExecutableEndOp)

terminator pseudo-op for the executable op


Syntax:

```
operation ::= `flow.executable_end` attr-dict
```


### `flow.executable` (::mlir::iree_compiler::IREE::Flow::ExecutableOp)

generic executable module

An executable module containing one or more public functions. The contents
of the functions are safe to dispatch and can be lowered further to
target-specific backend IR representations.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`sym_name` | ::mlir::StringAttr | string attribute

### `flow.return` (::mlir::iree_compiler::IREE::Flow::ReturnOp)

return from a flow.dispatch_region


Syntax:

```
operation ::= `flow.return` attr-dict ($operands^ `:` type($operands))?
```

Returns the given values from the region and back to the host code.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`operands` | any type

### `flow.tensor.clone` (::mlir::iree_compiler::IREE::Flow::TensorCloneOp)

performs a full tensor clone operation


Syntax:

```
operation ::= `flow.tensor.clone` $operand `:` type($result) (`{` $operand_dims^ `}`)?
              attr-dict-with-keyword
```

Clones the input tensor into an identical output tensor.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`operand` | ranked tensor of any type values
`operand_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values

### `flow.tensor.load` (::mlir::iree_compiler::IREE::Flow::TensorLoadOp)

loads a value from a tensor element


Syntax:

```
operation ::= `flow.tensor.load` $source (`[` $indices^ `]`)? `:`
              type($source) (`{` $source_dims^ `}`)?
              attr-dict-with-keyword
```

Returns the element at the given location from within the tensor.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`source` | ranked tensor of any type values
`source_dims` | index
`indices` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | index or signless integer or floating-point or vector of any type values

### `flow.tensor.reshape` (::mlir::iree_compiler::IREE::Flow::TensorReshapeOp)

reshapes a tensor


Syntax:

```
operation ::= `flow.tensor.reshape` $source `:`
              type($source) (`{` $source_dims^ `}`)? `->`
              type($result) (`{` $result_dims^ `}`)?
              attr-dict-with-keyword
```

Reshapes a tensor to a new shape without modifying the contents.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`source` | ranked tensor of any type values
`source_dims` | index
`result_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values

### `flow.tensor.slice` (::mlir::iree_compiler::IREE::Flow::TensorSliceOp)

slices out a subregion of a tensor


Syntax:

```
operation ::= `flow.tensor.slice` $source `[` $start_indices `for` $lengths `]` `:`
              type($source) (`{` $source_dims^ `}`)? `->`
              type($result) (`{` $result_dims^ `}`)?
              attr-dict-with-keyword
```

Clones a subregion of a tensor.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`source` | ranked tensor of any type values
`source_dims` | index
`start_indices` | index
`lengths` | index
`result_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values

### `flow.tensor.splat` (::mlir::iree_compiler::IREE::Flow::TensorSplatOp)

splats a value into a shaped tensor


Syntax:

```
operation ::= `flow.tensor.splat` $value `:` type($result) (`{` $result_dims^ `}`)?
              attr-dict-with-keyword
```

Returns a tensor initialized to the given primitive value.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`value` | index or signless integer or floating-point
`result_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values

### `flow.tensor.store` (::mlir::iree_compiler::IREE::Flow::TensorStoreOp)

stores a value into a tensor element


Syntax:

```
operation ::= `flow.tensor.store` $value `,` $target (`[` $indices^ `]`)? `:`
              type($target) (`{` $target_dims^ `}`)?
              attr-dict-with-keyword
```

Returns a tensor with the element at the given index set to the given value.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`value` | index or signless integer or floating-point or vector of any type values
`target` | ranked tensor of any type values
`target_dims` | index
`indices` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values

### `flow.tensor.trace` (::mlir::iree_compiler::IREE::Flow::TensorTraceOp)

trace value(s) operation


Syntax:

```
operation ::= `flow.tensor.trace` attr-dict ($operands^ `:` type($operands))?
```

Traces out to a runtime trace sink (console, log file, etc) the given
tensors and titles them with the given key. The key is informational only
and useful for titling/marking specific sets of tensors for easier
searching.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`key` | ::mlir::StringAttr | string attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`operands` | ranked tensor of any type values

### `flow.tensor.update` (::mlir::iree_compiler::IREE::Flow::TensorUpdateOp)

updates a tensor with the contents of another tensor


Syntax:

```
operation ::= `flow.tensor.update` $update `,` $target `[` $start_indices `]` `:`
              type($update) (`{` $update_dims^ `}`)? `->`
              custom<TiedResult>(type($result), $target_dims, $tied_operands)
              attr-dict-with-keyword
```

Updates the target tensor with the contents of the update tensor at the
given offset indices.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`tied_operands` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`target` | ranked tensor of any type values
`target_dims` | index
`start_indices` | index
`update` | ranked tensor of any type values
`update_dims` | index

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values

### `flow.variable.address` (::mlir::iree_compiler::IREE::Flow::VariableAddressOp)

returns an address reference to a variable


Syntax:

```
operation ::= `flow.variable.address` $variable attr-dict `:` type($result)
```

Returns the address of a variable as a typed reference. Can be used with the
variable load and store indirect ops.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`variable` | FlatSymbolRefAttr | symbol reference attribute

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | ranked tensor of any type values or index or signless integer or floating-point

### `flow.variable.load.indirect` (::mlir::iree_compiler::IREE::Flow::VariableLoadIndirectOp)

loads a value from a global variable


Syntax:

```
operation ::= `flow.variable.load.indirect` $variable attr-dict `:` type($variable) `->` type($result)
```

Returns a copy of the variable value.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`variable` | ranked tensor of any type values or index or signless integer or floating-point

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | any type

### `flow.variable.load` (::mlir::iree_compiler::IREE::Flow::VariableLoadOp)

loads a value from a global variable


Syntax:

```
operation ::= `flow.variable.load` $variable attr-dict `:` type($result)
```

Returns a copy of the variable value.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`variable` | FlatSymbolRefAttr | symbol reference attribute

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | any type

### `flow.variable` (::mlir::iree_compiler::IREE::Flow::VariableOp)

stateful variable declaration

Declares a persistent variable that maintains its value.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`sym_name` | ::mlir::StringAttr | string attribute
`type` | ::mlir::TypeAttr | any type attribute
`is_mutable` | ::mlir::UnitAttr | unit attribute
`initializer` | ::mlir::FlatSymbolRefAttr | flat symbol reference attribute
`initial_value` | ::mlir::Attribute | any attribute

### `flow.variable.store.indirect` (::mlir::iree_compiler::IREE::Flow::VariableStoreIndirectOp)

stores a value into a global variable


Syntax:

```
operation ::= `flow.variable.store.indirect` $value `,` $variable attr-dict `:` type($value) `->` type($variable)
```

Stores a copy of the value into a variable.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`value` | any type
`variable` | ranked tensor of any type values or index or signless integer or floating-point

### `flow.variable.store` (::mlir::iree_compiler::IREE::Flow::VariableStoreOp)

stores a value into a global variable


Syntax:

```
operation ::= `flow.variable.store` $value `,` $variable attr-dict `:` type($value)
```

Stores a copy of the value into a variable.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`variable` | FlatSymbolRefAttr | symbol reference attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`value` | any type
