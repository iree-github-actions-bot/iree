---
layout: default
permalink: ir-examples/mhlo-dot-vulkan-spirv
title: "mhlo-dot on vulkan-spirv"
parent: IR Conversion Examples
---

# mhlo-dot on vulkan-spirv
{: .no_toc }

This is an IR conversion example auto-generated by running `iree-opt`
over [mhlo-dot](https://github.com/google/iree/tree/main/iree/samples/ops/mhlo-dot.mlir).

### The command

```shell
iree-opt -iree-transformation-pipeline \
  -iree-hal-target-backends=vulkan-spirv \
  --print-ir-after-all \
  -mlir-disable-threading \
  -mlir-elide-elementsattrs-if-larger=8 \
  iree/samples/ops/mhlo-dot.mlir

```
### Input IR

{% raw %}
```
func @dot(%lhs: tensor<32x1024xf32>, %rhs: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes { iree.module.export } {
  %0 = "mhlo.dot"(%lhs, %rhs) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}
```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::SIP::MaterializeReflectionAttrsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After SymbolDCE

{% raw %}
```
module  {
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::{anonymous}::HLOToHLOPreprocessingPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After RemoveShapeConstraints

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After TosaToSCF

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After TosaToStandard

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After TosaToLinalgOnTensors

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module  {
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After SCFToStandard

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Inliner

{% raw %}
```
module  {
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::Shape::{anonymous}::ConvertShapeToShapex

{% raw %}
```
module  {
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::LegalizeInputTypesPass

{% raw %}
```
module  {
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::ExpandVariableDynamicDimsPass

{% raw %}
```
module  {
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::Shape::{anonymous}::ExpandFunctionDynamicDimsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::Shape::{anonymous}::TieDynamicShapesPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::Shape::{anonymous}::MaterializeShapeCalculationsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::Shape::{anonymous}::HoistShapeCalculations

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::PrePartitioningConversionPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = "mhlo.dot"(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::ConvertHLOToLinalgOnTensorsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::Convert1x1ConvToMatmulPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After ConvertElementwiseToLinalg

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After LinalgFoldUnitExtentDims

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::FusionOfTensorOpsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::{anonymous}::ConvertToFlowTensorOpsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %cst = constant 0.000000e+00 : f32
  %0 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
  %1 = linalg.fill(%0, %cst) : tensor<32x64xf32>, f32 -> tensor<32x64xf32> 
  %2 = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%1 : tensor<32x64xf32>) -> tensor<32x64xf32>
  return %2 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::{anonymous}::DispatchLinalgOnTensorsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c1 = constant 1 : index
  %0 = flow.dispatch.workgroups[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg3: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg4: !flow.dispatch.tensor<writeonly:32x64xf32>) {
    %cst = constant 0.000000e+00 : f32
    %c32_0 = constant 32 : index
    %c64_1 = constant 64 : index
    %1 = linalg.init_tensor [32, 64] : tensor<32x64xf32>
    %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
    %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
    %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
    %2 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_1, %workgroup_size_1]
    %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_1, %workgroup_size_1]
    scf.for %arg5 = %2 to %c32_0 step %3 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_0, %workgroup_size_0]
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_0, %workgroup_size_0]
      scf.for %arg6 = %4 to %c64_1 step %5 {
        %6 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 32)>(%arg5, %workgroup_size_1)
        %7 = flow.dispatch.tensor.load %arg2, offsets = [%arg5, 0], sizes = [%6, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
        %8 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 64)>(%arg6, %workgroup_size_0)
        %9 = flow.dispatch.tensor.load %arg3, offsets = [0, %arg6], sizes = [1024, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
        %10 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 32)>(%arg5, %workgroup_size_1)
        %11 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 64)>(%arg6, %workgroup_size_0)
        %12 = affine.min affine_map<(d0, d1) -> (-d0 + 32, d1)>(%arg5, %workgroup_size_1)
        %13 = affine.min affine_map<(d0, d1) -> (-d0 + 64, d1)>(%arg6, %workgroup_size_0)
        %14 = subtensor %1[%arg5, %arg6] [%12, %13] [1, 1] : tensor<32x64xf32> to tensor<?x?xf32>
        %15 = linalg.fill(%14, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
        %16 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%7, %9 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %16, %arg4, offsets = [%arg5, %arg6], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
      }
    }
    flow.return
  }
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c1 = constant 1 : index
  %0 = flow.dispatch.workgroups[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg3: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg4: !flow.dispatch.tensor<writeonly:32x64xf32>) {
    %cst = constant 0.000000e+00 : f32
    %c32_0 = constant 32 : index
    %c64_1 = constant 64 : index
    %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
    %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
    %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
    %1 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_1, %workgroup_size_1]
    %2 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_1, %workgroup_size_1]
    scf.for %arg5 = %1 to %c32_0 step %2 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_0, %workgroup_size_0]
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_0, %workgroup_size_0]
      scf.for %arg6 = %3 to %c64_1 step %4 {
        %5 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 32)>(%arg5, %workgroup_size_1)
        %6 = flow.dispatch.tensor.load %arg2, offsets = [%arg5, 0], sizes = [%5, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
        %7 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 64)>(%arg6, %workgroup_size_0)
        %8 = flow.dispatch.tensor.load %arg3, offsets = [0, %arg6], sizes = [1024, %7], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
        %9 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 32)>(%arg5, %workgroup_size_1)
        %10 = affine.min affine_map<(d0, d1) -> (d1, -d0 + 64)>(%arg6, %workgroup_size_0)
        %11 = affine.min affine_map<(d0, d1) -> (-d0 + 32, d1)>(%arg5, %workgroup_size_1)
        %12 = affine.min affine_map<(d0, d1) -> (-d0 + 64, d1)>(%arg6, %workgroup_size_0)
        %13 = linalg.init_tensor [%11, %12] : tensor<?x?xf32>
        %14 = linalg.fill(%13, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
        %15 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%6, %8 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%14 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %15, %arg4, offsets = [%arg5, %arg6], sizes = [%9, %10], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
      }
    }
    flow.return
  }
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::OutlineDispatchRegions2Pass

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0, d1) -> (d1, -d0 + 32)>
#map2 = affine_map<(d0, d1) -> (d1, -d0 + 64)>
#map3 = affine_map<(d0, d1) -> (-d0 + 32, d1)>
#map4 = affine_map<(d0, d1) -> (-d0 + 64, d1)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3, %workgroup_size_1)
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4, %workgroup_size_0)
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3, %workgroup_size_1)
            %9 = affine.min #map2(%arg4, %workgroup_size_0)
            %10 = affine.min #map3(%arg3, %workgroup_size_1)
            %11 = affine.min #map4(%arg4, %workgroup_size_0)
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c1 = constant 1 : index
    %0 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c1 = constant 1 : index
  %0 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::DeduplicateExecutablesPass

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0, d1) -> (d1, -d0 + 32)>
#map2 = affine_map<(d0, d1) -> (d1, -d0 + 64)>
#map3 = affine_map<(d0, d1) -> (-d0 + 32, d1)>
#map4 = affine_map<(d0, d1) -> (-d0 + 64, d1)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3, %workgroup_size_1)
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4, %workgroup_size_0)
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3, %workgroup_size_1)
            %9 = affine.min #map2(%arg4, %workgroup_size_0)
            %10 = affine.min #map3(%arg3, %workgroup_size_1)
            %11 = affine.min #map4(%arg4, %workgroup_size_0)
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c1 = constant 1 : index
    %0 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c1 = constant 1 : index
  %0 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c1 = constant 1 : index
  %0 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::{anonymous}::HoistUnstreamableOps

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c1 = constant 1 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %0 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c1 = constant 1 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %0 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::FormStreamsPass

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c1 = constant 1 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %0 = flow.ex.stream.fragment(%c64, %c32, %c1, %arg0, %arg1) : (index, index, index, tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
      (%arg2: index, %arg3: index, %arg4: index, %arg5: tensor<32x1024xf32>, %arg6: tensor<1024x64xf32>) -> tensor<32x64xf32> {
    %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%arg2, %arg3, %arg4](%arg5, %arg6) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    flow.return %1 : tensor<32x64xf32>
  }
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::Flow::OutlineLargeConstantsPass

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0, d1) -> (d1, -d0 + 32)>
#map2 = affine_map<(d0, d1) -> (d1, -d0 + 64)>
#map3 = affine_map<(d0, d1) -> (-d0 + 32, d1)>
#map4 = affine_map<(d0, d1) -> (-d0 + 64, d1)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3, %workgroup_size_1)
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4, %workgroup_size_0)
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3, %workgroup_size_1)
            %9 = affine.min #map2(%arg4, %workgroup_size_0)
            %10 = affine.min #map3(%arg3, %workgroup_size_1)
            %11 = affine.min #map4(%arg4, %workgroup_size_0)
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c1 = constant 1 : index
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %0 = flow.ex.stream.fragment(%c64, %c32, %c1, %arg0, %arg1) : (index, index, index, tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: index, %arg3: index, %arg4: index, %arg5: tensor<32x1024xf32>, %arg6: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%arg2, %arg3, %arg4](%arg5, %arg6) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
      (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c1 = constant 1 : index
    %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    flow.return %1 : tensor<32x64xf32>
  }
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
      (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c1 = constant 1 : index
    %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
    flow.return %1 : tensor<32x64xf32>
  }
  return %0 : tensor<32x64xf32>
}

```
{% endraw %}

### IR Dump After SymbolDCE

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0, d1) -> (d1, -d0 + 32)>
#map2 = affine_map<(d0, d1) -> (d1, -d0 + 64)>
#map3 = affine_map<(d0, d1) -> (-d0 + 32, d1)>
#map4 = affine_map<(d0, d1) -> (-d0 + 64, d1)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3, %workgroup_size_1)
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4, %workgroup_size_0)
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3, %workgroup_size_1)
            %9 = affine.min #map2(%arg4, %workgroup_size_0)
            %10 = affine.min #map3(%arg3, %workgroup_size_1)
            %11 = affine.min #map4(%arg4, %workgroup_size_0)
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0)[s0] -> (s0, -d0 + 32)>
#map2 = affine_map<(d0)[s0] -> (s0, -d0 + 64)>
#map3 = affine_map<(d0)[s0] -> (-d0 + 32, s0)>
#map4 = affine_map<(d0)[s0] -> (-d0 + 64, s0)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3)[%workgroup_size_1]
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4)[%workgroup_size_0]
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3)[%workgroup_size_1]
            %9 = affine.min #map2(%arg4)[%workgroup_size_0]
            %10 = affine.min #map3(%arg3)[%workgroup_size_1]
            %11 = affine.min #map4(%arg4)[%workgroup_size_0]
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::IdentifyConstantPoolsPass

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0)[s0] -> (s0, -d0 + 32)>
#map2 = affine_map<(d0)[s0] -> (s0, -d0 + 64)>
#map3 = affine_map<(d0)[s0] -> (-d0 + 32, s0)>
#map4 = affine_map<(d0)[s0] -> (-d0 + 64, s0)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3)[%workgroup_size_1]
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4)[%workgroup_size_0]
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3)[%workgroup_size_1]
            %9 = affine.min #map2(%arg4)[%workgroup_size_0]
            %10 = affine.min #map3(%arg3)[%workgroup_size_1]
            %11 = affine.min #map4(%arg4)[%workgroup_size_0]
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeConstantPoolBuffersPass

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0)[s0] -> (s0, -d0 + 32)>
#map2 = affine_map<(d0)[s0] -> (s0, -d0 + 64)>
#map3 = affine_map<(d0)[s0] -> (-d0 + 32, s0)>
#map4 = affine_map<(d0)[s0] -> (-d0 + 64, s0)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3)[%workgroup_size_1]
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4)[%workgroup_size_0]
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3)[%workgroup_size_1]
            %9 = affine.min #map2(%arg4)[%workgroup_size_0]
            %10 = affine.min #map3(%arg3)[%workgroup_size_1]
            %11 = affine.min #map4(%arg4)[%workgroup_size_0]
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0)[s0] -> (s0, -d0 + 32)>
#map2 = affine_map<(d0)[s0] -> (s0, -d0 + 64)>
#map3 = affine_map<(d0)[s0] -> (-d0 + 32, s0)>
#map4 = affine_map<(d0)[s0] -> (-d0 + 64, s0)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3)[%workgroup_size_1]
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4)[%workgroup_size_0]
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3)[%workgroup_size_1]
            %9 = affine.min #map2(%arg4)[%workgroup_size_0]
            %10 = affine.min #map3(%arg3)[%workgroup_size_1]
            %11 = affine.min #map4(%arg4)[%workgroup_size_0]
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After SymbolDCE

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0)[s0] -> (s0, -d0 + 32)>
#map2 = affine_map<(d0)[s0] -> (s0, -d0 + 64)>
#map3 = affine_map<(d0)[s0] -> (-d0 + 32, s0)>
#map4 = affine_map<(d0)[s0] -> (-d0 + 64, s0)>
module  {
  flow.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    flow.dispatch.entry @dot_dispatch_0 attributes {signature = (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>, workgroup_rank = 3 : index}
    module  {
      func @dot_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:32x1024xf32>, %arg1: !flow.dispatch.tensor<readonly:1024x64xf32>, %arg2: !flow.dispatch.tensor<writeonly:32x64xf32>) {
        %cst = constant 0.000000e+00 : f32
        %c32 = constant 32 : index
        %c64 = constant 64 : index
        %workgroup_size_0 = flow.dispatch.workgroup.size[0] : index
        %workgroup_size_1 = flow.dispatch.workgroup.size[1] : index
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %workgroup_id_1 = flow.dispatch.workgroup.id[1] : index
        %workgroup_count_1 = flow.dispatch.workgroup.count[1] : index
        %0 = affine.apply #map0()[%workgroup_id_1, %workgroup_size_1]
        %1 = affine.apply #map0()[%workgroup_count_1, %workgroup_size_1]
        scf.for %arg3 = %0 to %c32 step %1 {
          %2 = affine.apply #map0()[%workgroup_id_0, %workgroup_size_0]
          %3 = affine.apply #map0()[%workgroup_count_0, %workgroup_size_0]
          scf.for %arg4 = %2 to %c64 step %3 {
            %4 = affine.min #map1(%arg3)[%workgroup_size_1]
            %5 = flow.dispatch.tensor.load %arg0, offsets = [%arg3, 0], sizes = [%4, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
            %6 = affine.min #map2(%arg4)[%workgroup_size_0]
            %7 = flow.dispatch.tensor.load %arg1, offsets = [0, %arg4], sizes = [1024, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
            %8 = affine.min #map1(%arg3)[%workgroup_size_1]
            %9 = affine.min #map2(%arg4)[%workgroup_size_0]
            %10 = affine.min #map3(%arg3)[%workgroup_size_1]
            %11 = affine.min #map4(%arg4)[%workgroup_size_0]
            %12 = linalg.init_tensor [%10, %11] : tensor<?x?xf32>
            %13 = linalg.fill(%12, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
            %14 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%5, %7 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%13 : tensor<?x?xf32>) -> tensor<?x?xf32>
            flow.dispatch.tensor.store %14, %arg2, offsets = [%arg3, %arg4], sizes = [%8, %9], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
          }
        }
        return
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeInterfaces2Pass

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0)[s0] -> (s0, -d0 + 32)>
#map2 = affine_map<(d0)[s0] -> (s0, -d0 + 64)>
#map3 = affine_map<(d0)[s0] -> (-d0 + 32, s0)>
#map4 = affine_map<(d0)[s0] -> (-d0 + 64, s0)>
module  {
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()}
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        func @dot_dispatch_0() {
          %c0 = constant 0 : index
          %cst = constant 0.000000e+00 : f32
          %c32 = constant 32 : index
          %c64 = constant 64 : index
          %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
          %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
          %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
          %workgroup_size_x = hal.interface.workgroup.size[0] : index
          %workgroup_size_y = hal.interface.workgroup.size[1] : index
          %workgroup_id_x = hal.interface.workgroup.id[0] : index
          %workgroup_count_x = hal.interface.workgroup.count[0] : index
          %workgroup_id_y = hal.interface.workgroup.id[1] : index
          %workgroup_count_y = hal.interface.workgroup.count[1] : index
          %3 = affine.apply #map0()[%workgroup_id_y, %workgroup_size_y]
          %4 = affine.apply #map0()[%workgroup_count_y, %workgroup_size_y]
          scf.for %arg0 = %3 to %c32 step %4 {
            %5 = affine.apply #map0()[%workgroup_id_x, %workgroup_size_x]
            %6 = affine.apply #map0()[%workgroup_count_x, %workgroup_size_x]
            scf.for %arg1 = %5 to %c64 step %6 {
              %7 = affine.min #map1(%arg0)[%workgroup_size_y]
              %8 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%7, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
              %9 = affine.min #map2(%arg1)[%workgroup_size_x]
              %10 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [1024, %9], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
              %11 = affine.min #map1(%arg0)[%workgroup_size_y]
              %12 = affine.min #map2(%arg1)[%workgroup_size_x]
              %13 = affine.min #map3(%arg0)[%workgroup_size_y]
              %14 = affine.min #map4(%arg1)[%workgroup_size_x]
              %15 = linalg.init_tensor [%13, %14] : tensor<?x?xf32>
              %16 = linalg.fill(%15, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
              %17 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
              flow.dispatch.tensor.store %17, %2, offsets = [%arg0, %arg1], sizes = [%11, %12], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
            }
          }
          return
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) {hal.bindings = [#hal.ex.operand_buffer<"s0b0_ro_external", 0 : index>, #hal.ex.operand_buffer<"s0b1_ro_external", 1 : index>, #hal.ex.result_buffer<"s0b2_xw_external", 0 : index>]} : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeInterfacesPass

{% raw %}
```
#map0 = affine_map<()[s0, s1] -> (s0 * s1)>
#map1 = affine_map<(d0)[s0] -> (s0, -d0 + 32)>
#map2 = affine_map<(d0)[s0] -> (s0, -d0 + 64)>
#map3 = affine_map<(d0)[s0] -> (-d0 + 32, s0)>
#map4 = affine_map<(d0)[s0] -> (-d0 + 64, s0)>
module  {
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()}
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        func @dot_dispatch_0() {
          %c0 = constant 0 : index
          %cst = constant 0.000000e+00 : f32
          %c32 = constant 32 : index
          %c64 = constant 64 : index
          %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
          %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
          %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
          %workgroup_size_x = hal.interface.workgroup.size[0] : index
          %workgroup_size_y = hal.interface.workgroup.size[1] : index
          %workgroup_id_x = hal.interface.workgroup.id[0] : index
          %workgroup_count_x = hal.interface.workgroup.count[0] : index
          %workgroup_id_y = hal.interface.workgroup.id[1] : index
          %workgroup_count_y = hal.interface.workgroup.count[1] : index
          %3 = affine.apply #map0()[%workgroup_id_y, %workgroup_size_y]
          %4 = affine.apply #map0()[%workgroup_count_y, %workgroup_size_y]
          scf.for %arg0 = %3 to %c32 step %4 {
            %5 = affine.apply #map0()[%workgroup_id_x, %workgroup_size_x]
            %6 = affine.apply #map0()[%workgroup_count_x, %workgroup_size_x]
            scf.for %arg1 = %5 to %c64 step %6 {
              %7 = affine.min #map1(%arg0)[%workgroup_size_y]
              %8 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%7, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
              %9 = affine.min #map2(%arg1)[%workgroup_size_x]
              %10 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [1024, %9], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
              %11 = affine.min #map1(%arg0)[%workgroup_size_y]
              %12 = affine.min #map2(%arg1)[%workgroup_size_x]
              %13 = affine.min #map3(%arg0)[%workgroup_size_y]
              %14 = affine.min #map4(%arg1)[%workgroup_size_x]
              %15 = linalg.init_tensor [%13, %14] : tensor<?x?xf32>
              %16 = linalg.fill(%15, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
              %17 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
              flow.dispatch.tensor.store %17, %2, offsets = [%arg0, %arg1], sizes = [%11, %12], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
            }
          }
          return
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>) -> tensor<32x64xf32> attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %0 = flow.ex.stream.fragment(%arg0, %arg1) : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32> =
        (%arg2: tensor<32x1024xf32>, %arg3: tensor<1024x64xf32>) -> tensor<32x64xf32> {
      %c64 = constant 64 : index
      %c32 = constant 32 : index
      %c1 = constant 1 : index
      %1 = flow.dispatch @dot_dispatch_0::@dot_dispatch_0[%c64, %c32, %c1](%arg2, %arg3) {hal.bindings = [#hal.ex.operand_buffer<"s0b0_ro_external", 0 : index>, #hal.ex.operand_buffer<"s0b1_ro_external", 1 : index>, #hal.ex.result_buffer<"s0b2_xw_external", 0 : index>]} : (tensor<32x1024xf32>, tensor<1024x64xf32>) -> tensor<32x64xf32>
      flow.return %1 : tensor<32x64xf32>
    }
    return %0 : tensor<32x64xf32>
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::PropagateConstantWorkgroupInfoPass

{% raw %}
```
hal.executable.target @vulkan_spirv, filter="vulkan*" {
  hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()}
  module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
    func @dot_dispatch_0() {
      %c0 = constant 0 : index
      %cst = constant 0.000000e+00 : f32
      %c32 = constant 32 : index
      %c64 = constant 64 : index
      %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
      %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
      %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
      %workgroup_size_x = hal.interface.workgroup.size[0] : index
      %workgroup_size_y = hal.interface.workgroup.size[1] : index
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %workgroup_id_y = hal.interface.workgroup.id[1] : index
      %workgroup_count_y = hal.interface.workgroup.count[1] : index
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
      scf.for %arg0 = %3 to %c32 step %4 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
        %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
        scf.for %arg1 = %5 to %c64 step %6 {
          %7 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
          %8 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%7, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
          %9 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
          %10 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [1024, %9], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
          %11 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
          %12 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
          %13 = affine.min affine_map<(d0)[s0] -> (-d0 + 32, s0)>(%arg0)[%workgroup_size_y]
          %14 = affine.min affine_map<(d0)[s0] -> (-d0 + 64, s0)>(%arg1)[%workgroup_size_x]
          %15 = linalg.init_tensor [%13, %14] : tensor<?x?xf32>
          %16 = linalg.fill(%15, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
          %17 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
          flow.dispatch.tensor.store %17, %2, offsets = [%arg0, %arg1], sizes = [%11, %12], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
        }
      }
      return
    }
    hal.interface @io attributes {sym_visibility = "private"} {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot_dispatch_0() {
  %c0 = constant 0 : index
  %cst = constant 0.000000e+00 : f32
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
  %workgroup_size_x = hal.interface.workgroup.size[0] : index
  %workgroup_size_y = hal.interface.workgroup.size[1] : index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
  %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
  scf.for %arg0 = %3 to %c32 step %4 {
    %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
    %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
    scf.for %arg1 = %5 to %c64 step %6 {
      %7 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %8 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%7, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
      %9 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %10 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [1024, %9], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
      %11 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %12 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %13 = affine.min affine_map<(d0)[s0] -> (-d0 + 32, s0)>(%arg0)[%workgroup_size_y]
      %14 = affine.min affine_map<(d0)[s0] -> (-d0 + 64, s0)>(%arg1)[%workgroup_size_x]
      %15 = linalg.init_tensor [%13, %14] : tensor<?x?xf32>
      %16 = linalg.fill(%15, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
      %17 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %17, %2, offsets = [%arg0, %arg1], sizes = [%11, %12], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
    }
  }
  return
}

```
{% endraw %}

### IR Dump After Inliner

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() {
    %c0 = constant 0 : index
    %cst = constant 0.000000e+00 : f32
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
    %workgroup_size_x = hal.interface.workgroup.size[0] : index
    %workgroup_size_y = hal.interface.workgroup.size[1] : index
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
    %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
    scf.for %arg0 = %3 to %c32 step %4 {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
      %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
      scf.for %arg1 = %5 to %c64 step %6 {
        %7 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
        %8 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%7, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
        %9 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
        %10 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [1024, %9], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
        %11 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
        %12 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
        %13 = affine.min affine_map<(d0)[s0] -> (-d0 + 32, s0)>(%arg0)[%workgroup_size_y]
        %14 = affine.min affine_map<(d0)[s0] -> (-d0 + 64, s0)>(%arg1)[%workgroup_size_x]
        %15 = linalg.init_tensor [%13, %14] : tensor<?x?xf32>
        %16 = linalg.fill(%15, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
        %17 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %2, offsets = [%arg0, %arg1], sizes = [%11, %12], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::BufferAllocViewCleanUpPass

{% raw %}
```
func @dot_dispatch_0() {
  %c0 = constant 0 : index
  %cst = constant 0.000000e+00 : f32
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
  %workgroup_size_x = hal.interface.workgroup.size[0] : index
  %workgroup_size_y = hal.interface.workgroup.size[1] : index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
  %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
  scf.for %arg0 = %3 to %c32 step %4 {
    %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
    %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
    scf.for %arg1 = %5 to %c64 step %6 {
      %7 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %8 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%7, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
      %9 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %10 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [1024, %9], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
      %11 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %12 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %13 = affine.min affine_map<(d0)[s0] -> (-d0 + 32, s0)>(%arg0)[%workgroup_size_y]
      %14 = affine.min affine_map<(d0)[s0] -> (-d0 + 64, s0)>(%arg1)[%workgroup_size_x]
      %15 = linalg.init_tensor [%13, %14] : tensor<?x?xf32>
      %16 = linalg.fill(%15, %cst) : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
      %17 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %17, %2, offsets = [%arg0, %arg1], sizes = [%11, %12], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:32x64xf32>
    }
  }
  return
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::LinalgBufferizePass

{% raw %}
```
func @dot_dispatch_0() {
  %c0 = constant 0 : index
  %cst = constant 0.000000e+00 : f32
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
  %2 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %3 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
  %4 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %5 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
  %workgroup_size_x = hal.interface.workgroup.size[0] : index
  %workgroup_size_y = hal.interface.workgroup.size[1] : index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
  %7 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
  scf.for %arg0 = %6 to %c32 step %7 {
    %8 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
    %9 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
    scf.for %arg1 = %8 to %c64 step %9 {
      %10 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %11 = memref.subview %0[%arg0, 0] [%10, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
      %12 = flow.dispatch.tensor.load %1, offsets = [%arg0, 0], sizes = [%10, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:32x1024xf32> -> tensor<?x1024xf32>
      %13 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %14 = memref.subview %2[0, %arg1] [1024, %13] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %15 = flow.dispatch.tensor.load %3, offsets = [0, %arg1], sizes = [1024, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:1024x64xf32> -> tensor<1024x?xf32>
      %16 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %17 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %18 = memref.subview %4[%arg0, %arg1] [%16, %17] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %19 = affine.min affine_map<(d0)[s0] -> (-d0 + 32, s0)>(%arg0)[%workgroup_size_y]
      %20 = affine.min affine_map<(d0)[s0] -> (-d0 + 64, s0)>(%arg1)[%workgroup_size_x]
      %21 = linalg.init_tensor [%19, %20] : tensor<?x?xf32>
      linalg.fill(%18, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
      %22 = linalg.fill(%21, %cst) {__internal_linalg_transform__ = "workgroup"} : tensor<?x?xf32>, f32 -> tensor<?x?xf32> 
      linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%11, %14 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%18 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
      %23 = linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%12, %15 : tensor<?x1024xf32>, tensor<1024x?xf32>) outs(%22 : tensor<?x?xf32>) -> tensor<?x?xf32>
    }
  }
  return
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot_dispatch_0() {
  %c0 = constant 0 : index
  %cst = constant 0.000000e+00 : f32
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
  %2 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %3 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
  %4 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %5 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
  %workgroup_size_x = hal.interface.workgroup.size[0] : index
  %workgroup_size_y = hal.interface.workgroup.size[1] : index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
  %7 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
  scf.for %arg0 = %6 to %c32 step %7 {
    %8 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
    %9 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
    scf.for %arg1 = %8 to %c64 step %9 {
      %10 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %11 = memref.subview %0[%arg0, 0] [%10, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
      %12 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %13 = memref.subview %2[0, %arg1] [1024, %12] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %14 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %15 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %16 = memref.subview %4[%arg0, %arg1] [%14, %15] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      linalg.fill(%16, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
      linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%11, %13 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%16 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
    }
  }
  return
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot_dispatch_0() {
  %c0 = constant 0 : index
  %cst = constant 0.000000e+00 : f32
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : !flow.dispatch.tensor<readonly:32x1024xf32>
  %2 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %3 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : !flow.dispatch.tensor<readonly:1024x64xf32>
  %4 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %5 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : !flow.dispatch.tensor<writeonly:32x64xf32>
  %workgroup_size_x = hal.interface.workgroup.size[0] : index
  %workgroup_size_y = hal.interface.workgroup.size[1] : index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
  %7 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
  scf.for %arg0 = %6 to %c32 step %7 {
    %8 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
    %9 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
    scf.for %arg1 = %8 to %c64 step %9 {
      %10 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %11 = memref.subview %0[%arg0, 0] [%10, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
      %12 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %13 = memref.subview %2[0, %arg1] [1024, %12] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %14 = memref.subview %4[%arg0, %arg1] [%10, %12] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      linalg.fill(%14, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
      linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%11, %13 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%14 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
    }
  }
  return
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::BufferAllocViewCleanUpPass

{% raw %}
```
func @dot_dispatch_0() {
  %c0 = constant 0 : index
  %cst = constant 0.000000e+00 : f32
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %workgroup_size_x = hal.interface.workgroup.size[0] : index
  %workgroup_size_y = hal.interface.workgroup.size[1] : index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
  %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
  scf.for %arg0 = %3 to %c32 step %4 {
    %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
    %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
    scf.for %arg1 = %5 to %c64 step %6 {
      %7 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
      %8 = memref.subview %0[%arg0, 0] [%7, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
      %9 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
      %10 = memref.subview %1[0, %arg1] [1024, %9] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %11 = memref.subview %2[%arg0, %arg1] [%7, %9] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      linalg.fill(%11, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
      linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%11 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
    }
  }
  return
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() {
    %c0 = constant 0 : index
    %cst = constant 0.000000e+00 : f32
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_size_x = hal.interface.workgroup.size[0] : index
    %workgroup_size_y = hal.interface.workgroup.size[1] : index
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
    %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
    scf.for %arg0 = %3 to %c32 step %4 {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
      %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
      scf.for %arg1 = %5 to %c64 step %6 {
        %7 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
        %8 = memref.subview %0[%arg0, 0] [%7, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
        %9 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
        %10 = memref.subview %1[0, %arg1] [1024, %9] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %11 = memref.subview %2[%arg0, %arg1] [%7, %9] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        linalg.fill(%11, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
        linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%11 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() {
    %c0 = constant 0 : index
    %cst = constant 0.000000e+00 : f32
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_size_x = hal.interface.workgroup.size[0] : index
    %workgroup_size_y = hal.interface.workgroup.size[1] : index
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %workgroup_size_y]
    %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_y, %workgroup_size_y]
    scf.for %arg0 = %3 to %c32 step %4 {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %workgroup_size_x]
      %6 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_count_x, %workgroup_size_x]
      scf.for %arg1 = %5 to %c64 step %6 {
        %7 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 32)>(%arg0)[%workgroup_size_y]
        %8 = memref.subview %0[%arg0, 0] [%7, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
        %9 = affine.min affine_map<(d0)[s0] -> (s0, -d0 + 64)>(%arg1)[%workgroup_size_x]
        %10 = memref.subview %1[0, %arg1] [1024, %9] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %11 = memref.subview %2[%arg0, %arg1] [%7, %9] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        linalg.fill(%11, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
        linalg.matmul {__internal_linalg_transform__ = "workgroup"} ins(%8, %10 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%11 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::ConcretizeTileAmongWorkgroupsPass

{% raw %}
```
hal.executable.target @vulkan_spirv, filter="vulkan*" {
  hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
  ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
    %c4 = constant 4 : index
    %c4_0 = constant 4 : index
    %c1 = constant 1 : index
    hal.return %c4, %c4_0, %c1 : index, index, index
  }
  module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
    func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
      %c0 = constant 0 : index
      %cst = constant 0.000000e+00 : f32
      %c16 = constant 16 : index
      %c8 = constant 8 : index
      %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
      %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
      %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_id_y = hal.interface.workgroup.id[1] : index
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %c8]
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %c16]
      %5 = affine.min affine_map<(d0)[s0] -> (8, -d0 + 32)>(%3)[%c8]
      %6 = memref.subview %0[%3, 0] [%5, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
      %7 = affine.min affine_map<(d0)[s0] -> (16, -d0 + 64)>(%4)[%c16]
      %8 = memref.subview %1[0, %4] [1024, %7] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %9 = memref.subview %2[%3, %4] [%5, %7] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      linalg.fill(%9, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
      linalg.matmul {__internal_linalg_transform__ = "workgroup", is_root_op} ins(%6, %8 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%9 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
      return
    }
    hal.interface @io attributes {sym_visibility = "private"} {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::TileAndVectorizeInOneWorkgroupPass

{% raw %}
```
hal.executable.target @vulkan_spirv, filter="vulkan*" {
  hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
  ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
    %c4 = constant 4 : index
    %c4_0 = constant 4 : index
    %c1 = constant 1 : index
    hal.return %c4, %c4_0, %c1 : index, index, index
  }
  module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
    func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
      %c0 = constant 0 : index
      %cst = constant 0.000000e+00 : f32
      %c16 = constant 16 : index
      %c8 = constant 8 : index
      %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
      %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
      %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_id_y = hal.interface.workgroup.id[1] : index
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_y, %c8]
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%workgroup_id_x, %c16]
      %5 = affine.min affine_map<(d0)[s0] -> (8, -d0 + 32)>(%3)[%c8]
      %6 = memref.subview %0[%3, 0] [%5, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
      %7 = affine.min affine_map<(d0)[s0] -> (16, -d0 + 64)>(%4)[%c16]
      %8 = memref.subview %1[0, %4] [1024, %7] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %9 = memref.subview %2[%3, %4] [%5, %7] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      linalg.fill(%9, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
      linalg.matmul {__internal_linalg_transform__ = "workgroup", is_root_op} ins(%6, %8 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%9 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
      return
    }
    hal.interface @io attributes {sym_visibility = "private"} {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %c0 = constant 0 : index
    %cst = constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 8)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 16)>()[%workgroup_id_x]
    %5 = affine.min affine_map<()[s0] -> (8, s0 * -8 + 32)>()[%workgroup_id_y]
    %6 = memref.subview %0[%3, 0] [%5, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
    %7 = affine.min affine_map<()[s0] -> (16, s0 * -16 + 64)>()[%workgroup_id_x]
    %8 = memref.subview %1[0, %4] [1024, %7] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    %9 = memref.subview %2[%3, %4] [%5, %7] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    linalg.fill(%9, %cst) {__internal_linalg_transform__ = "workgroup"} : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>, f32 
    linalg.matmul {__internal_linalg_transform__ = "workgroup", is_root_op} ins(%6, %8 : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>, memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>) outs(%9 : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>)
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::ConvertToGPUPass

{% raw %}
```
hal.executable.target @vulkan_spirv, filter="vulkan*" {
  hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
  ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
    %c4 = constant 4 : index
    %c4_0 = constant 4 : index
    %c1 = constant 1 : index
    hal.return %c4, %c4_0, %c1 : index, index, index
  }
  module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
    func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
      %c0 = constant 0 : index
      %cst = constant 0.000000e+00 : f32
      %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
      %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
      %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_id_y = hal.interface.workgroup.id[1] : index
      %3 = affine.apply affine_map<()[s0] -> (s0 * 8)>()[%workgroup_id_y]
      %4 = affine.apply affine_map<()[s0] -> (s0 * 16)>()[%workgroup_id_x]
      %5 = affine.min affine_map<()[s0] -> (8, s0 * -8 + 32)>()[%workgroup_id_y]
      %6 = memref.subview %0[%3, 0] [%5, 1024] [1, 1] : memref<32x1024xf32> to memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
      %7 = affine.min affine_map<()[s0] -> (16, s0 * -16 + 64)>()[%workgroup_id_x]
      %8 = memref.subview %1[0, %4] [1024, %7] [1, 1] : memref<1024x64xf32> to memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %9 = memref.subview %2[%3, %4] [%5, %7] [1, 1] : memref<32x64xf32> to memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      %c0_0 = constant 0 : index
      %c1 = constant 1 : index
      %c0_1 = constant 0 : index
      %c1_2 = constant 1 : index
      %10 = "gpu.thread_id"() {dimension = "x"} : () -> index
      %11 = "gpu.block_dim"() {dimension = "x"} : () -> index
      %12 = "gpu.thread_id"() {dimension = "y"} : () -> index
      %13 = "gpu.block_dim"() {dimension = "y"} : () -> index
      %14 = muli %c1_2, %12 : index
      %15 = addi %c0_1, %14 : index
      %16 = muli %c1_2, %13 : index
      %17 = muli %c1_2, %10 : index
      %18 = addi %c0_1, %17 : index
      %19 = muli %c1_2, %11 : index
      scf.for %arg0 = %15 to %5 step %16 {
        scf.for %arg1 = %18 to %7 step %19 {
          %30 = affine.apply affine_map<(d0) -> (d0)>(%arg0)
          %31 = affine.apply affine_map<(d0) -> (d0)>(%arg1)
          %32 = memref.load %9[%30, %31] : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          %33 = affine.apply affine_map<(d0) -> (d0)>(%arg0)
          %34 = affine.apply affine_map<(d0) -> (d0)>(%arg1)
          memref.store %cst, %9[%33, %34] : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        }
      }
      %c0_3 = constant 0 : index
      %c1_4 = constant 1 : index
      %c1024 = constant 1024 : index
      %c0_5 = constant 0 : index
      %c1024_6 = constant 1024 : index
      %c1_7 = constant 1 : index
      %c0_8 = constant 0 : index
      %c1_9 = constant 1 : index
      %c0_10 = constant 0 : index
      %c1_11 = constant 1 : index
      %20 = "gpu.thread_id"() {dimension = "x"} : () -> index
      %21 = "gpu.block_dim"() {dimension = "x"} : () -> index
      %22 = "gpu.thread_id"() {dimension = "y"} : () -> index
      %23 = "gpu.block_dim"() {dimension = "y"} : () -> index
      %24 = muli %c1_11, %22 : index
      %25 = addi %c0_10, %24 : index
      %26 = muli %c1_11, %23 : index
      %27 = muli %c1_11, %20 : index
      %28 = addi %c0_10, %27 : index
      %29 = muli %c1_11, %21 : index
      scf.for %arg0 = %25 to %5 step %26 {
        scf.for %arg1 = %28 to %7 step %29 {
          scf.for %arg2 = %c0_10 to %c1024 step %c1_11 {
            %30 = affine.apply affine_map<(d0) -> (d0)>(%arg0)
            %31 = affine.apply affine_map<(d0) -> (d0)>(%arg2)
            %32 = memref.load %6[%30, %31] : memref<?x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
            %33 = affine.apply affine_map<(d0) -> (d0)>(%arg2)
            %34 = affine.apply affine_map<(d0) -> (d0)>(%arg1)
            %35 = memref.load %8[%33, %34] : memref<1024x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
            %36 = affine.apply affine_map<(d0) -> (d0)>(%arg0)
            %37 = affine.apply affine_map<(d0) -> (d0)>(%arg1)
            %38 = memref.load %9[%36, %37] : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
            %39 = affine.apply affine_map<(d0) -> (d0)>(%arg0)
            %40 = affine.apply affine_map<(d0) -> (d0)>(%arg1)
            %41 = mulf %32, %35 : f32
            %42 = addf %38, %41 : f32
            memref.store %42, %9[%39, %40] : memref<?x?xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          }
        }
      }
      return
    }
    hal.interface @io attributes {sym_visibility = "private"} {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::ConvertVectorToGPUPass

{% raw %}
```
func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
  %cst = constant 0.000000e+00 : f32
  %c8 = constant 8 : index
  %c16 = constant 16 : index
  %c1024 = constant 1024 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 8)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 16)>()[%workgroup_id_x]
  %5 = memref.subview %0[%3, 0] [8, 1024] [1, 1] : memref<32x1024xf32> to memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
  %6 = memref.subview %1[0, %4] [1024, 16] [1, 1] : memref<1024x64xf32> to memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
  %7 = memref.subview %2[%3, %4] [8, 16] [1, 1] : memref<32x64xf32> to memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
  %8 = "gpu.thread_id"() {dimension = "x"} : () -> index
  %9 = "gpu.block_dim"() {dimension = "x"} : () -> index
  %10 = "gpu.thread_id"() {dimension = "y"} : () -> index
  %11 = "gpu.block_dim"() {dimension = "y"} : () -> index
  scf.for %arg0 = %10 to %c8 step %11 {
    scf.for %arg1 = %8 to %c16 step %9 {
      memref.store %cst, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    }
  }
  %12 = "gpu.thread_id"() {dimension = "x"} : () -> index
  %13 = "gpu.block_dim"() {dimension = "x"} : () -> index
  %14 = "gpu.thread_id"() {dimension = "y"} : () -> index
  %15 = "gpu.block_dim"() {dimension = "y"} : () -> index
  scf.for %arg0 = %14 to %c8 step %15 {
    scf.for %arg1 = %12 to %c16 step %13 {
      scf.for %arg2 = %c0 to %c1024 step %c1 {
        %16 = memref.load %5[%arg0, %arg2] : memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
        %17 = memref.load %6[%arg2, %arg1] : memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %18 = memref.load %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %19 = mulf %16, %17 : f32
        %20 = addf %18, %19 : f32
        memref.store %20, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      }
    }
  }
  return
}

```
{% endraw %}

### IR Dump After ConvertAffineToStandard

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %c8_0 = constant 8 : index
    %3 = muli %workgroup_id_y, %c8_0 : index
    %c16_1 = constant 16 : index
    %4 = muli %workgroup_id_x, %c16_1 : index
    %5 = memref.subview %0[%3, 0] [8, 1024] [1, 1] : memref<32x1024xf32> to memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
    %6 = memref.subview %1[0, %4] [1024, 16] [1, 1] : memref<1024x64xf32> to memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    %7 = memref.subview %2[%3, %4] [8, 16] [1, 1] : memref<32x64xf32> to memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    %8 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %9 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %10 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %11 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %10 to %c8 step %11 {
      scf.for %arg1 = %8 to %c16 step %9 {
        memref.store %cst, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      }
    }
    %12 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %13 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %14 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %15 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %14 to %c8 step %15 {
      scf.for %arg1 = %12 to %c16 step %13 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %16 = memref.load %5[%arg0, %arg2] : memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
          %17 = memref.load %6[%arg2, %arg1] : memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          %18 = memref.load %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          %19 = mulf %16, %17 : f32
          %20 = addf %18, %19 : f32
          memref.store %20, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = memref.subview %0[%3, 0] [8, 1024] [1, 1] : memref<32x1024xf32> to memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
    %6 = memref.subview %1[0, %4] [1024, 16] [1, 1] : memref<1024x64xf32> to memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    %7 = memref.subview %2[%3, %4] [8, 16] [1, 1] : memref<32x64xf32> to memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    %8 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %9 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %10 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %11 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %10 to %c8 step %11 {
      scf.for %arg1 = %8 to %c16 step %9 {
        memref.store %cst, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      }
    }
    %12 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %13 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %14 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %15 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %14 to %c8 step %15 {
      scf.for %arg1 = %12 to %c16 step %13 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %16 = memref.load %5[%arg0, %arg2] : memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
          %17 = memref.load %6[%arg2, %arg1] : memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          %18 = memref.load %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          %19 = mulf %16, %17 : f32
          %20 = addf %18, %19 : f32
          memref.store %20, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = memref.subview %0[%3, 0] [8, 1024] [1, 1] : memref<32x1024xf32> to memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
    %6 = memref.subview %1[0, %4] [1024, 16] [1, 1] : memref<1024x64xf32> to memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    %7 = memref.subview %2[%3, %4] [8, 16] [1, 1] : memref<32x64xf32> to memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    %8 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %9 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %10 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %11 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %10 to %c8 step %11 {
      scf.for %arg1 = %8 to %c16 step %9 {
        memref.store %cst, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      }
    }
    scf.for %arg0 = %10 to %c8 step %11 {
      scf.for %arg1 = %8 to %c16 step %9 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %12 = memref.load %5[%arg0, %arg2] : memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
          %13 = memref.load %6[%arg2, %arg1] : memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          %14 = memref.load %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
          %15 = mulf %12, %13 : f32
          %16 = addf %14, %15 : f32
          memref.store %16, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::ResolveShapeOpsPass

{% raw %}
```
func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
  %cst = constant 0.000000e+00 : f32
  %c1024 = constant 1024 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c8 = constant 8 : index
  %c16 = constant 16 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = muli %workgroup_id_y, %c8 : index
  %4 = muli %workgroup_id_x, %c16 : index
  %5 = memref.subview %0[%3, 0] [8, 1024] [1, 1] : memref<32x1024xf32> to memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
  %6 = memref.subview %1[0, %4] [1024, 16] [1, 1] : memref<1024x64xf32> to memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
  %7 = memref.subview %2[%3, %4] [8, 16] [1, 1] : memref<32x64xf32> to memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
  %8 = "gpu.thread_id"() {dimension = "x"} : () -> index
  %9 = "gpu.block_dim"() {dimension = "x"} : () -> index
  %10 = "gpu.thread_id"() {dimension = "y"} : () -> index
  %11 = "gpu.block_dim"() {dimension = "y"} : () -> index
  scf.for %arg0 = %10 to %c8 step %11 {
    scf.for %arg1 = %8 to %c16 step %9 {
      memref.store %cst, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    }
  }
  scf.for %arg0 = %10 to %c8 step %11 {
    scf.for %arg1 = %8 to %c16 step %9 {
      scf.for %arg2 = %c0 to %c1024 step %c1 {
        %12 = memref.load %5[%arg0, %arg2] : memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
        %13 = memref.load %6[%arg2, %arg1] : memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %14 = memref.load %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %15 = mulf %12, %13 : f32
        %16 = addf %14, %15 : f32
        memref.store %16, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      }
    }
  }
  return
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::VectorTransferOptimizationPass

{% raw %}
```
func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
  %cst = constant 0.000000e+00 : f32
  %c1024 = constant 1024 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c8 = constant 8 : index
  %c16 = constant 16 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = muli %workgroup_id_y, %c8 : index
  %4 = muli %workgroup_id_x, %c16 : index
  %5 = memref.subview %0[%3, 0] [8, 1024] [1, 1] : memref<32x1024xf32> to memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
  %6 = memref.subview %1[0, %4] [1024, 16] [1, 1] : memref<1024x64xf32> to memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
  %7 = memref.subview %2[%3, %4] [8, 16] [1, 1] : memref<32x64xf32> to memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
  %8 = "gpu.thread_id"() {dimension = "x"} : () -> index
  %9 = "gpu.block_dim"() {dimension = "x"} : () -> index
  %10 = "gpu.thread_id"() {dimension = "y"} : () -> index
  %11 = "gpu.block_dim"() {dimension = "y"} : () -> index
  scf.for %arg0 = %10 to %c8 step %11 {
    scf.for %arg1 = %8 to %c16 step %9 {
      memref.store %cst, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
    }
  }
  scf.for %arg0 = %10 to %c8 step %11 {
    scf.for %arg1 = %8 to %c16 step %9 {
      scf.for %arg2 = %c0 to %c1024 step %c1 {
        %12 = memref.load %5[%arg0, %arg2] : memref<8x1024xf32, affine_map<(d0, d1)[s0] -> (d0 * 1024 + s0 + d1)>>
        %13 = memref.load %6[%arg2, %arg1] : memref<1024x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %14 = memref.load %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
        %15 = mulf %12, %13 : f32
        %16 = addf %14, %15 : f32
        memref.store %16, %7[%arg0, %arg1] : memref<8x16xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + s0 + d1)>>
      }
    }
  }
  return
}

```
{% endraw %}

### IR Dump After FoldSubViewOps

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        memref.store %cst, %2[%9, %10] : memref<32x64xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = memref.load %0[%9, %arg2] : memref<32x1024xf32>
          %11 = addi %4, %arg1 : index
          %12 = memref.load %1[%arg2, %11] : memref<1024x64xf32>
          %13 = addi %3, %arg0 : index
          %14 = addi %4, %arg1 : index
          %15 = memref.load %2[%13, %14] : memref<32x64xf32>
          %16 = mulf %10, %12 : f32
          %17 = addf %15, %16 : f32
          %18 = addi %3, %arg0 : index
          %19 = addi %4, %arg1 : index
          memref.store %17, %2[%18, %19] : memref<32x64xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        memref.store %cst, %2[%9, %10] : memref<32x64xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = memref.load %0[%9, %arg2] : memref<32x1024xf32>
          %11 = addi %4, %arg1 : index
          %12 = memref.load %1[%arg2, %11] : memref<1024x64xf32>
          %13 = addi %3, %arg0 : index
          %14 = addi %4, %arg1 : index
          %15 = memref.load %2[%13, %14] : memref<32x64xf32>
          %16 = mulf %10, %12 : f32
          %17 = addf %15, %16 : f32
          %18 = addi %3, %arg0 : index
          %19 = addi %4, %arg1 : index
          memref.store %17, %2[%18, %19] : memref<32x64xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        memref.store %cst, %2[%9, %10] : memref<32x64xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = memref.load %0[%9, %arg2] : memref<32x1024xf32>
          %11 = addi %4, %arg1 : index
          %12 = memref.load %1[%arg2, %11] : memref<1024x64xf32>
          %13 = memref.load %2[%9, %11] : memref<32x64xf32>
          %14 = mulf %10, %12 : f32
          %15 = addf %13, %14 : f32
          memref.store %15, %2[%9, %11] : memref<32x64xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::VectorizeMemRefPass

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        memref.store %cst, %2[%9, %10] : memref<32x64xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = memref.load %0[%9, %arg2] : memref<32x1024xf32>
          %11 = addi %4, %arg1 : index
          %12 = memref.load %1[%arg2, %11] : memref<1024x64xf32>
          %13 = memref.load %2[%9, %11] : memref<32x64xf32>
          %14 = mulf %10, %12 : f32
          %15 = addf %13, %14 : f32
          memref.store %15, %2[%9, %11] : memref<32x64xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::ForOpCanonicalizationPass

{% raw %}
```
func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
  %cst = constant 0.000000e+00 : f32
  %c1024 = constant 1024 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c8 = constant 8 : index
  %c16 = constant 16 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = muli %workgroup_id_y, %c8 : index
  %4 = muli %workgroup_id_x, %c16 : index
  %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
  %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
  %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
  %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
  scf.for %arg0 = %7 to %c8 step %8 {
    scf.for %arg1 = %5 to %c16 step %6 {
      %9 = addi %3, %arg0 : index
      %10 = addi %4, %arg1 : index
      memref.store %cst, %2[%9, %10] : memref<32x64xf32>
    }
  }
  scf.for %arg0 = %7 to %c8 step %8 {
    scf.for %arg1 = %5 to %c16 step %6 {
      scf.for %arg2 = %c0 to %c1024 step %c1 {
        %9 = addi %3, %arg0 : index
        %10 = memref.load %0[%9, %arg2] : memref<32x1024xf32>
        %11 = addi %4, %arg1 : index
        %12 = memref.load %1[%arg2, %11] : memref<1024x64xf32>
        %13 = memref.load %2[%9, %11] : memref<32x64xf32>
        %14 = mulf %10, %12 : f32
        %15 = addf %13, %14 : f32
        memref.store %15, %2[%9, %11] : memref<32x64xf32>
      }
    }
  }
  return
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        memref.store %cst, %2[%9, %10] : memref<32x64xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = memref.load %0[%9, %arg2] : memref<32x1024xf32>
          %11 = addi %4, %arg1 : index
          %12 = memref.load %1[%arg2, %11] : memref<1024x64xf32>
          %13 = memref.load %2[%9, %11] : memref<32x64xf32>
          %14 = mulf %10, %12 : f32
          %15 = addf %13, %14 : f32
          memref.store %15, %2[%9, %11] : memref<32x64xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<32x1024xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<1024x64xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<32x64xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        memref.store %cst, %2[%9, %10] : memref<32x64xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = memref.load %0[%9, %arg2] : memref<32x1024xf32>
          %11 = addi %4, %arg1 : index
          %12 = memref.load %1[%arg2, %11] : memref<1024x64xf32>
          %13 = memref.load %2[%9, %11] : memref<32x64xf32>
          %14 = mulf %10, %12 : f32
          %15 = addf %13, %14 : f32
          memref.store %15, %2[%9, %11] : memref<32x64xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::FlattenMemRefSubspanPass

{% raw %}
```
func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
  %cst = constant 0.000000e+00 : f32
  %c8 = constant 8 : index
  %c16 = constant 16 : index
  %c1024 = constant 1024 : index
  %c0 = constant 0 : index
  %c64 = constant 64 : index
  %c1 = constant 1 : index
  %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<?xf32>
  %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<?xf32>
  %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = muli %workgroup_id_y, %c8 : index
  %4 = muli %workgroup_id_x, %c16 : index
  %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
  %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
  %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
  %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
  scf.for %arg0 = %7 to %c8 step %8 {
    scf.for %arg1 = %5 to %c16 step %6 {
      %9 = addi %3, %arg0 : index
      %10 = addi %4, %arg1 : index
      %11 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%9, %c64, %c0]
      %12 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%10, %c1, %11]
      memref.store %cst, %2[%12] : memref<?xf32>
    }
  }
  scf.for %arg0 = %7 to %c8 step %8 {
    scf.for %arg1 = %5 to %c16 step %6 {
      scf.for %arg2 = %c0 to %c1024 step %c1 {
        %9 = addi %3, %arg0 : index
        %10 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%9, %c1024, %c0]
        %11 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%arg2, %c1, %10]
        %12 = memref.load %0[%11] : memref<?xf32>
        %13 = addi %4, %arg1 : index
        %14 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%arg2, %c64, %c0]
        %15 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%13, %c1, %14]
        %16 = memref.load %1[%15] : memref<?xf32>
        %17 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%9, %c64, %c0]
        %18 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%13, %c1, %17]
        %19 = memref.load %2[%18] : memref<?xf32>
        %20 = mulf %12, %16 : f32
        %21 = addf %19, %20 : f32
        %22 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%9, %c64, %c0]
        %23 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * s1 + s2)>()[%13, %c1, %22]
        memref.store %21, %2[%23] : memref<?xf32>
      }
    }
  }
  return
}

```
{% endraw %}

### IR Dump After ConvertAffineToStandard

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c64 = constant 64 : index
    %c1 = constant 1 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<?xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<?xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        %11 = muli %9, %c64 : index
        %12 = addi %11, %c0 : index
        %13 = muli %10, %c1 : index
        %14 = addi %13, %12 : index
        memref.store %cst, %2[%14] : memref<?xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = muli %9, %c1024 : index
          %11 = addi %10, %c0 : index
          %12 = muli %arg2, %c1 : index
          %13 = addi %12, %11 : index
          %14 = memref.load %0[%13] : memref<?xf32>
          %15 = addi %4, %arg1 : index
          %16 = muli %arg2, %c64 : index
          %17 = addi %16, %c0 : index
          %18 = muli %15, %c1 : index
          %19 = addi %18, %17 : index
          %20 = memref.load %1[%19] : memref<?xf32>
          %21 = muli %9, %c64 : index
          %22 = addi %21, %c0 : index
          %23 = muli %15, %c1 : index
          %24 = addi %23, %22 : index
          %25 = memref.load %2[%24] : memref<?xf32>
          %26 = mulf %14, %20 : f32
          %27 = addf %25, %26 : f32
          %28 = muli %9, %c64 : index
          %29 = addi %28, %c0 : index
          %30 = muli %15, %c1 : index
          %31 = addi %30, %29 : index
          memref.store %27, %2[%31] : memref<?xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c64 = constant 64 : index
    %c1 = constant 1 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<?xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<?xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        %11 = muli %9, %c64 : index
        %12 = addi %10, %11 : index
        memref.store %cst, %2[%12] : memref<?xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = muli %9, %c1024 : index
          %11 = addi %arg2, %10 : index
          %12 = memref.load %0[%11] : memref<?xf32>
          %13 = addi %4, %arg1 : index
          %14 = muli %arg2, %c64 : index
          %15 = addi %13, %14 : index
          %16 = memref.load %1[%15] : memref<?xf32>
          %17 = muli %9, %c64 : index
          %18 = addi %13, %17 : index
          %19 = memref.load %2[%18] : memref<?xf32>
          %20 = mulf %12, %16 : f32
          %21 = addf %19, %20 : f32
          %22 = muli %9, %c64 : index
          %23 = addi %13, %22 : index
          memref.store %21, %2[%23] : memref<?xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  func @dot_dispatch_0() attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
    %cst = constant 0.000000e+00 : f32
    %c8 = constant 8 : index
    %c16 = constant 16 : index
    %c1024 = constant 1024 : index
    %c0 = constant 0 : index
    %c64 = constant 64 : index
    %c1 = constant 1 : index
    %0 = hal.interface.binding.subspan @io::@s0b0_ro_external[%c0] : memref<?xf32>
    %1 = hal.interface.binding.subspan @io::@s0b1_ro_external[%c0] : memref<?xf32>
    %2 = hal.interface.binding.subspan @io::@s0b2_xw_external[%c0] : memref<?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = muli %workgroup_id_y, %c8 : index
    %4 = muli %workgroup_id_x, %c16 : index
    %5 = "gpu.thread_id"() {dimension = "x"} : () -> index
    %6 = "gpu.block_dim"() {dimension = "x"} : () -> index
    %7 = "gpu.thread_id"() {dimension = "y"} : () -> index
    %8 = "gpu.block_dim"() {dimension = "y"} : () -> index
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        %9 = addi %3, %arg0 : index
        %10 = addi %4, %arg1 : index
        %11 = muli %9, %c64 : index
        %12 = addi %10, %11 : index
        memref.store %cst, %2[%12] : memref<?xf32>
      }
    }
    scf.for %arg0 = %7 to %c8 step %8 {
      scf.for %arg1 = %5 to %c16 step %6 {
        scf.for %arg2 = %c0 to %c1024 step %c1 {
          %9 = addi %3, %arg0 : index
          %10 = muli %9, %c1024 : index
          %11 = addi %arg2, %10 : index
          %12 = memref.load %0[%11] : memref<?xf32>
          %13 = addi %4, %arg1 : index
          %14 = muli %arg2, %c64 : index
          %15 = addi %13, %14 : index
          %16 = memref.load %1[%15] : memref<?xf32>
          %17 = muli %9, %c64 : index
          %18 = addi %13, %17 : index
          %19 = memref.load %2[%18] : memref<?xf32>
          %20 = mulf %12, %16 : f32
          %21 = addf %19, %20 : f32
          memref.store %21, %2[%18] : memref<?xf32>
        }
      }
    }
    return
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::{anonymous}::ConvertToSPIRVPass

{% raw %}
```
module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
  spv.module Logical GLSL450 {
    spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
    spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
    spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    spv.func @dot_dispatch_0() "None" attributes {spv.entry_point_abi = {local_size = dense<[16, 8, 1]> : vector<3xi32>}} {
      %0 = spv.Constant 0.000000e+00 : f32
      %1 = spv.Constant 8 : i32
      %2 = spv.Constant 16 : i32
      %3 = spv.Constant 1024 : i32
      %4 = spv.Constant 0 : i32
      %5 = spv.Constant 64 : i32
      %6 = spv.Constant 1 : i32
      %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
      %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
      %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
      %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
      %11 = spv.Load "Input" %10 : vector<3xi32>
      %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
      %13 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
      %14 = spv.Load "Input" %13 : vector<3xi32>
      %15 = spv.CompositeExtract %14[1 : i32] : vector<3xi32>
      %16 = spv.IMul %15, %1 : i32
      %17 = spv.IMul %12, %2 : i32
      %18 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
      %19 = spv.Load "Input" %18 : vector<3xi32>
      %20 = spv.CompositeExtract %19[0 : i32] : vector<3xi32>
      %21 = spv.Constant 16 : i32
      %22 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
      %23 = spv.Load "Input" %22 : vector<3xi32>
      %24 = spv.CompositeExtract %23[1 : i32] : vector<3xi32>
      %25 = spv.Constant 8 : i32
      spv.mlir.loop {
        spv.Branch ^bb1(%24 : i32)
      ^bb1(%26: i32):  // 2 preds: ^bb0, ^bb2
        %27 = spv.SLessThan %26, %1 : i32
        spv.BranchConditional %27, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        spv.mlir.loop {
          spv.Branch ^bb1(%20 : i32)
        ^bb1(%29: i32):  // 2 preds: ^bb0, ^bb2
          %30 = spv.SLessThan %29, %2 : i32
          spv.BranchConditional %30, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %31 = spv.IAdd %16, %26 : i32
          %32 = spv.IAdd %17, %29 : i32
          %33 = spv.IMul %31, %5 : i32
          %34 = spv.IAdd %32, %33 : i32
          %35 = spv.Constant 0 : i32
          %36 = spv.Constant 0 : i32
          %37 = spv.Constant 1 : i32
          %38 = spv.IMul %37, %34 : i32
          %39 = spv.IAdd %36, %38 : i32
          %40 = spv.AccessChain %9[%35, %39] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          spv.Store "StorageBuffer" %40, %0 : f32
          %41 = spv.IAdd %29, %21 : i32
          spv.Branch ^bb1(%41 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        %28 = spv.IAdd %26, %25 : i32
        spv.Branch ^bb1(%28 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      spv.mlir.loop {
        spv.Branch ^bb1(%24 : i32)
      ^bb1(%26: i32):  // 2 preds: ^bb0, ^bb2
        %27 = spv.SLessThan %26, %1 : i32
        spv.BranchConditional %27, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        spv.mlir.loop {
          spv.Branch ^bb1(%20 : i32)
        ^bb1(%29: i32):  // 2 preds: ^bb0, ^bb2
          %30 = spv.SLessThan %29, %2 : i32
          spv.BranchConditional %30, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          spv.mlir.loop {
            spv.Branch ^bb1(%4 : i32)
          ^bb1(%32: i32):  // 2 preds: ^bb0, ^bb2
            %33 = spv.SLessThan %32, %3 : i32
            spv.BranchConditional %33, ^bb2, ^bb3
          ^bb2:  // pred: ^bb1
            %34 = spv.IAdd %16, %26 : i32
            %35 = spv.IMul %34, %3 : i32
            %36 = spv.IAdd %32, %35 : i32
            %37 = spv.Constant 0 : i32
            %38 = spv.Constant 0 : i32
            %39 = spv.Constant 1 : i32
            %40 = spv.IMul %39, %36 : i32
            %41 = spv.IAdd %38, %40 : i32
            %42 = spv.AccessChain %7[%37, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
            %43 = spv.Load "StorageBuffer" %42 : f32
            %44 = spv.IAdd %17, %29 : i32
            %45 = spv.IMul %32, %5 : i32
            %46 = spv.IAdd %44, %45 : i32
            %47 = spv.Constant 0 : i32
            %48 = spv.Constant 0 : i32
            %49 = spv.Constant 1 : i32
            %50 = spv.IMul %49, %46 : i32
            %51 = spv.IAdd %48, %50 : i32
            %52 = spv.AccessChain %8[%47, %51] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
            %53 = spv.Load "StorageBuffer" %52 : f32
            %54 = spv.IMul %34, %5 : i32
            %55 = spv.IAdd %44, %54 : i32
            %56 = spv.Constant 0 : i32
            %57 = spv.Constant 0 : i32
            %58 = spv.Constant 1 : i32
            %59 = spv.IMul %58, %55 : i32
            %60 = spv.IAdd %57, %59 : i32
            %61 = spv.AccessChain %9[%56, %60] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
            %62 = spv.Load "StorageBuffer" %61 : f32
            %63 = spv.FMul %43, %53 : f32
            %64 = spv.FAdd %62, %63 : f32
            %65 = spv.Constant 0 : i32
            %66 = spv.Constant 0 : i32
            %67 = spv.Constant 1 : i32
            %68 = spv.IMul %67, %55 : i32
            %69 = spv.IAdd %66, %68 : i32
            %70 = spv.AccessChain %9[%65, %69] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
            spv.Store "StorageBuffer" %70, %64 : f32
            %71 = spv.IAdd %32, %6 : i32
            spv.Branch ^bb1(%71 : i32)
          ^bb3:  // pred: ^bb1
            spv.mlir.merge
          }
          %31 = spv.IAdd %29, %21 : i32
          spv.Branch ^bb1(%31 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        %28 = spv.IAdd %26, %25 : i32
        spv.Branch ^bb1(%28 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      spv.Return
    }
  }
  hal.interface @io attributes {sym_visibility = "private"} {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
}

```
{% endraw %}

### IR Dump After SPIRVLowerABIAttributes

{% raw %}
```
spv.module Logical GLSL450 {
  spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.func @dot_dispatch_0() "None" {
    %0 = spv.Constant 0.000000e+00 : f32
    %1 = spv.Constant 8 : i32
    %2 = spv.Constant 16 : i32
    %3 = spv.Constant 1024 : i32
    %4 = spv.Constant 0 : i32
    %5 = spv.Constant 64 : i32
    %6 = spv.Constant 1 : i32
    %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
    %11 = spv.Load "Input" %10 : vector<3xi32>
    %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
    %13 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
    %14 = spv.Load "Input" %13 : vector<3xi32>
    %15 = spv.CompositeExtract %14[1 : i32] : vector<3xi32>
    %16 = spv.IMul %15, %1 : i32
    %17 = spv.IMul %12, %2 : i32
    %18 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
    %19 = spv.Load "Input" %18 : vector<3xi32>
    %20 = spv.CompositeExtract %19[0 : i32] : vector<3xi32>
    %21 = spv.Constant 16 : i32
    %22 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
    %23 = spv.Load "Input" %22 : vector<3xi32>
    %24 = spv.CompositeExtract %23[1 : i32] : vector<3xi32>
    %25 = spv.Constant 8 : i32
    spv.mlir.loop {
      spv.Branch ^bb1(%24 : i32)
    ^bb1(%26: i32):  // 2 preds: ^bb0, ^bb2
      %27 = spv.SLessThan %26, %1 : i32
      spv.BranchConditional %27, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%20 : i32)
      ^bb1(%29: i32):  // 2 preds: ^bb0, ^bb2
        %30 = spv.SLessThan %29, %2 : i32
        spv.BranchConditional %30, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        %31 = spv.IAdd %16, %26 : i32
        %32 = spv.IAdd %17, %29 : i32
        %33 = spv.IMul %31, %5 : i32
        %34 = spv.IAdd %32, %33 : i32
        %35 = spv.Constant 0 : i32
        %36 = spv.Constant 0 : i32
        %37 = spv.Constant 1 : i32
        %38 = spv.IMul %37, %34 : i32
        %39 = spv.IAdd %36, %38 : i32
        %40 = spv.AccessChain %9[%35, %39] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
        spv.Store "StorageBuffer" %40, %0 : f32
        %41 = spv.IAdd %29, %21 : i32
        spv.Branch ^bb1(%41 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %28 = spv.IAdd %26, %25 : i32
      spv.Branch ^bb1(%28 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.mlir.loop {
      spv.Branch ^bb1(%24 : i32)
    ^bb1(%26: i32):  // 2 preds: ^bb0, ^bb2
      %27 = spv.SLessThan %26, %1 : i32
      spv.BranchConditional %27, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%20 : i32)
      ^bb1(%29: i32):  // 2 preds: ^bb0, ^bb2
        %30 = spv.SLessThan %29, %2 : i32
        spv.BranchConditional %30, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        spv.mlir.loop {
          spv.Branch ^bb1(%4 : i32)
        ^bb1(%32: i32):  // 2 preds: ^bb0, ^bb2
          %33 = spv.SLessThan %32, %3 : i32
          spv.BranchConditional %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = spv.IAdd %16, %26 : i32
          %35 = spv.IMul %34, %3 : i32
          %36 = spv.IAdd %32, %35 : i32
          %37 = spv.Constant 0 : i32
          %38 = spv.Constant 0 : i32
          %39 = spv.Constant 1 : i32
          %40 = spv.IMul %39, %36 : i32
          %41 = spv.IAdd %38, %40 : i32
          %42 = spv.AccessChain %7[%37, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %43 = spv.Load "StorageBuffer" %42 : f32
          %44 = spv.IAdd %17, %29 : i32
          %45 = spv.IMul %32, %5 : i32
          %46 = spv.IAdd %44, %45 : i32
          %47 = spv.Constant 0 : i32
          %48 = spv.Constant 0 : i32
          %49 = spv.Constant 1 : i32
          %50 = spv.IMul %49, %46 : i32
          %51 = spv.IAdd %48, %50 : i32
          %52 = spv.AccessChain %8[%47, %51] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %53 = spv.Load "StorageBuffer" %52 : f32
          %54 = spv.IMul %34, %5 : i32
          %55 = spv.IAdd %44, %54 : i32
          %56 = spv.Constant 0 : i32
          %57 = spv.Constant 0 : i32
          %58 = spv.Constant 1 : i32
          %59 = spv.IMul %58, %55 : i32
          %60 = spv.IAdd %57, %59 : i32
          %61 = spv.AccessChain %9[%56, %60] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %62 = spv.Load "StorageBuffer" %61 : f32
          %63 = spv.FMul %43, %53 : f32
          %64 = spv.FAdd %62, %63 : f32
          %65 = spv.Constant 0 : i32
          %66 = spv.Constant 0 : i32
          %67 = spv.Constant 1 : i32
          %68 = spv.IMul %67, %55 : i32
          %69 = spv.IAdd %66, %68 : i32
          %70 = spv.AccessChain %9[%65, %69] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          spv.Store "StorageBuffer" %70, %64 : f32
          %71 = spv.IAdd %32, %6 : i32
          spv.Branch ^bb1(%71 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        %31 = spv.IAdd %29, %21 : i32
        spv.Branch ^bb1(%31 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %28 = spv.IAdd %26, %25 : i32
      spv.Branch ^bb1(%28 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.Return
  }
  spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
  spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
spv.module Logical GLSL450 {
  spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.func @dot_dispatch_0() "None" {
    %0 = spv.Constant 0.000000e+00 : f32
    %1 = spv.Constant 1024 : i32
    %2 = spv.Constant 64 : i32
    %3 = spv.Constant 1 : i32
    %4 = spv.Constant 16 : i32
    %5 = spv.Constant 8 : i32
    %6 = spv.Constant 0 : i32
    %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
    %11 = spv.Load "Input" %10 : vector<3xi32>
    %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
    %13 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
    %14 = spv.Load "Input" %13 : vector<3xi32>
    %15 = spv.CompositeExtract %14[1 : i32] : vector<3xi32>
    %16 = spv.IMul %15, %5 : i32
    %17 = spv.IMul %12, %4 : i32
    %18 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
    %19 = spv.Load "Input" %18 : vector<3xi32>
    %20 = spv.CompositeExtract %19[0 : i32] : vector<3xi32>
    %21 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
    %22 = spv.Load "Input" %21 : vector<3xi32>
    %23 = spv.CompositeExtract %22[1 : i32] : vector<3xi32>
    spv.mlir.loop {
      spv.Branch ^bb1(%23 : i32)
    ^bb1(%24: i32):  // 2 preds: ^bb0, ^bb2
      %25 = spv.SLessThan %24, %5 : i32
      spv.BranchConditional %25, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%20 : i32)
      ^bb1(%27: i32):  // 2 preds: ^bb0, ^bb2
        %28 = spv.SLessThan %27, %4 : i32
        spv.BranchConditional %28, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        %29 = spv.IAdd %16, %24 : i32
        %30 = spv.IAdd %17, %27 : i32
        %31 = spv.IMul %29, %2 : i32
        %32 = spv.IAdd %30, %31 : i32
        %33 = spv.AccessChain %9[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
        spv.Store "StorageBuffer" %33, %0 : f32
        %34 = spv.IAdd %27, %4 : i32
        spv.Branch ^bb1(%34 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %26 = spv.IAdd %24, %5 : i32
      spv.Branch ^bb1(%26 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.mlir.loop {
      spv.Branch ^bb1(%23 : i32)
    ^bb1(%24: i32):  // 2 preds: ^bb0, ^bb2
      %25 = spv.SLessThan %24, %5 : i32
      spv.BranchConditional %25, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%20 : i32)
      ^bb1(%27: i32):  // 2 preds: ^bb0, ^bb2
        %28 = spv.SLessThan %27, %4 : i32
        spv.BranchConditional %28, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        spv.mlir.loop {
          spv.Branch ^bb1(%6 : i32)
        ^bb1(%30: i32):  // 2 preds: ^bb0, ^bb2
          %31 = spv.SLessThan %30, %1 : i32
          spv.BranchConditional %31, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %32 = spv.IAdd %16, %24 : i32
          %33 = spv.IMul %32, %1 : i32
          %34 = spv.IAdd %30, %33 : i32
          %35 = spv.AccessChain %7[%6, %34] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %36 = spv.Load "StorageBuffer" %35 : f32
          %37 = spv.IAdd %17, %27 : i32
          %38 = spv.IMul %30, %2 : i32
          %39 = spv.IAdd %37, %38 : i32
          %40 = spv.AccessChain %8[%6, %39] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %41 = spv.Load "StorageBuffer" %40 : f32
          %42 = spv.IMul %32, %2 : i32
          %43 = spv.IAdd %37, %42 : i32
          %44 = spv.AccessChain %9[%6, %43] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %45 = spv.Load "StorageBuffer" %44 : f32
          %46 = spv.FMul %36, %41 : f32
          %47 = spv.FAdd %45, %46 : f32
          %48 = spv.AccessChain %9[%6, %43] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          spv.Store "StorageBuffer" %48, %47 : f32
          %49 = spv.IAdd %30, %3 : i32
          spv.Branch ^bb1(%49 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        %29 = spv.IAdd %27, %4 : i32
        spv.Branch ^bb1(%29 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %26 = spv.IAdd %24, %5 : i32
      spv.Branch ^bb1(%26 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.Return
  }
  spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
  spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
spv.module Logical GLSL450 {
  spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.func @dot_dispatch_0() "None" {
    %0 = spv.Constant 0.000000e+00 : f32
    %1 = spv.Constant 1024 : i32
    %2 = spv.Constant 64 : i32
    %3 = spv.Constant 1 : i32
    %4 = spv.Constant 16 : i32
    %5 = spv.Constant 8 : i32
    %6 = spv.Constant 0 : i32
    %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
    %11 = spv.Load "Input" %10 : vector<3xi32>
    %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
    %13 = spv.Load "Input" %10 : vector<3xi32>
    %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
    %15 = spv.IMul %14, %5 : i32
    %16 = spv.IMul %12, %4 : i32
    %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
    %18 = spv.Load "Input" %17 : vector<3xi32>
    %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
    %20 = spv.Load "Input" %17 : vector<3xi32>
    %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
    spv.mlir.loop {
      spv.Branch ^bb1(%21 : i32)
    ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
      %23 = spv.SLessThan %22, %5 : i32
      spv.BranchConditional %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%19 : i32)
      ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
        %26 = spv.SLessThan %25, %4 : i32
        spv.BranchConditional %26, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        %27 = spv.IAdd %15, %22 : i32
        %28 = spv.IAdd %16, %25 : i32
        %29 = spv.IMul %27, %2 : i32
        %30 = spv.IAdd %28, %29 : i32
        %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
        spv.Store "StorageBuffer" %31, %0 : f32
        %32 = spv.IAdd %25, %4 : i32
        spv.Branch ^bb1(%32 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %24 = spv.IAdd %22, %5 : i32
      spv.Branch ^bb1(%24 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.mlir.loop {
      spv.Branch ^bb1(%21 : i32)
    ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
      %23 = spv.SLessThan %22, %5 : i32
      spv.BranchConditional %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%19 : i32)
      ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
        %26 = spv.SLessThan %25, %4 : i32
        spv.BranchConditional %26, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        spv.mlir.loop {
          spv.Branch ^bb1(%6 : i32)
        ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
          %29 = spv.SLessThan %28, %1 : i32
          spv.BranchConditional %29, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %30 = spv.IAdd %15, %22 : i32
          %31 = spv.IMul %30, %1 : i32
          %32 = spv.IAdd %28, %31 : i32
          %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %34 = spv.Load "StorageBuffer" %33 : f32
          %35 = spv.IAdd %16, %25 : i32
          %36 = spv.IMul %28, %2 : i32
          %37 = spv.IAdd %35, %36 : i32
          %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %39 = spv.Load "StorageBuffer" %38 : f32
          %40 = spv.IMul %30, %2 : i32
          %41 = spv.IAdd %35, %40 : i32
          %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %43 = spv.Load "StorageBuffer" %42 : f32
          %44 = spv.FMul %34, %39 : f32
          %45 = spv.FAdd %43, %44 : f32
          spv.Store "StorageBuffer" %42, %45 : f32
          %46 = spv.IAdd %28, %3 : i32
          spv.Branch ^bb1(%46 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        %27 = spv.IAdd %25, %4 : i32
        spv.Branch ^bb1(%27 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %24 = spv.IAdd %22, %5 : i32
      spv.Branch ^bb1(%24 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.Return
  }
  spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
  spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
}

```
{% endraw %}

### IR Dump After SPIRVUpdateVCE

{% raw %}
```
spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
  spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
  spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
  spv.func @dot_dispatch_0() "None" {
    %0 = spv.Constant 0.000000e+00 : f32
    %1 = spv.Constant 1024 : i32
    %2 = spv.Constant 64 : i32
    %3 = spv.Constant 1 : i32
    %4 = spv.Constant 16 : i32
    %5 = spv.Constant 8 : i32
    %6 = spv.Constant 0 : i32
    %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
    %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
    %11 = spv.Load "Input" %10 : vector<3xi32>
    %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
    %13 = spv.Load "Input" %10 : vector<3xi32>
    %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
    %15 = spv.IMul %14, %5 : i32
    %16 = spv.IMul %12, %4 : i32
    %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
    %18 = spv.Load "Input" %17 : vector<3xi32>
    %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
    %20 = spv.Load "Input" %17 : vector<3xi32>
    %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
    spv.mlir.loop {
      spv.Branch ^bb1(%21 : i32)
    ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
      %23 = spv.SLessThan %22, %5 : i32
      spv.BranchConditional %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%19 : i32)
      ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
        %26 = spv.SLessThan %25, %4 : i32
        spv.BranchConditional %26, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        %27 = spv.IAdd %15, %22 : i32
        %28 = spv.IAdd %16, %25 : i32
        %29 = spv.IMul %27, %2 : i32
        %30 = spv.IAdd %28, %29 : i32
        %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
        spv.Store "StorageBuffer" %31, %0 : f32
        %32 = spv.IAdd %25, %4 : i32
        spv.Branch ^bb1(%32 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %24 = spv.IAdd %22, %5 : i32
      spv.Branch ^bb1(%24 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.mlir.loop {
      spv.Branch ^bb1(%21 : i32)
    ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
      %23 = spv.SLessThan %22, %5 : i32
      spv.BranchConditional %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      spv.mlir.loop {
        spv.Branch ^bb1(%19 : i32)
      ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
        %26 = spv.SLessThan %25, %4 : i32
        spv.BranchConditional %26, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        spv.mlir.loop {
          spv.Branch ^bb1(%6 : i32)
        ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
          %29 = spv.SLessThan %28, %1 : i32
          spv.BranchConditional %29, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %30 = spv.IAdd %15, %22 : i32
          %31 = spv.IMul %30, %1 : i32
          %32 = spv.IAdd %28, %31 : i32
          %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %34 = spv.Load "StorageBuffer" %33 : f32
          %35 = spv.IAdd %16, %25 : i32
          %36 = spv.IMul %28, %2 : i32
          %37 = spv.IAdd %35, %36 : i32
          %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %39 = spv.Load "StorageBuffer" %38 : f32
          %40 = spv.IMul %30, %2 : i32
          %41 = spv.IAdd %35, %40 : i32
          %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
          %43 = spv.Load "StorageBuffer" %42 : f32
          %44 = spv.FMul %34, %39 : f32
          %45 = spv.FAdd %43, %44 : f32
          spv.Store "StorageBuffer" %42, %45 : f32
          %46 = spv.IAdd %28, %3 : i32
          spv.Branch ^bb1(%46 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        %27 = spv.IAdd %25, %4 : i32
        spv.Branch ^bb1(%27 : i32)
      ^bb3:  // pred: ^bb1
        spv.mlir.merge
      }
      %24 = spv.IAdd %22, %5 : i32
      spv.Branch ^bb1(%24 : i32)
    ^bb3:  // pred: ^bb1
      spv.mlir.merge
    }
    spv.Return
  }
  spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
  spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::TranslateExecutablesPass

{% raw %}
```
hal.executable.target @vulkan_spirv, filter="vulkan*" {
  hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
  ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
    %c4 = constant 4 : index
    %c4_0 = constant 4 : index
    %c1 = constant 1 : index
    hal.return %c4, %c4_0, %c1 : index, index, index
  }
  module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
    spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
      spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
      spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
      spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
      spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
      spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
      spv.func @dot_dispatch_0() "None" {
        %0 = spv.Constant 0.000000e+00 : f32
        %1 = spv.Constant 1024 : i32
        %2 = spv.Constant 64 : i32
        %3 = spv.Constant 1 : i32
        %4 = spv.Constant 16 : i32
        %5 = spv.Constant 8 : i32
        %6 = spv.Constant 0 : i32
        %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
        %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
        %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
        %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
        %11 = spv.Load "Input" %10 : vector<3xi32>
        %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
        %13 = spv.Load "Input" %10 : vector<3xi32>
        %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
        %15 = spv.IMul %14, %5 : i32
        %16 = spv.IMul %12, %4 : i32
        %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
        %18 = spv.Load "Input" %17 : vector<3xi32>
        %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
        %20 = spv.Load "Input" %17 : vector<3xi32>
        %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
        spv.mlir.loop {
          spv.Branch ^bb1(%21 : i32)
        ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
          %23 = spv.SLessThan %22, %5 : i32
          spv.BranchConditional %23, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          spv.mlir.loop {
            spv.Branch ^bb1(%19 : i32)
          ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
            %26 = spv.SLessThan %25, %4 : i32
            spv.BranchConditional %26, ^bb2, ^bb3
          ^bb2:  // pred: ^bb1
            %27 = spv.IAdd %15, %22 : i32
            %28 = spv.IAdd %16, %25 : i32
            %29 = spv.IMul %27, %2 : i32
            %30 = spv.IAdd %28, %29 : i32
            %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
            spv.Store "StorageBuffer" %31, %0 : f32
            %32 = spv.IAdd %25, %4 : i32
            spv.Branch ^bb1(%32 : i32)
          ^bb3:  // pred: ^bb1
            spv.mlir.merge
          }
          %24 = spv.IAdd %22, %5 : i32
          spv.Branch ^bb1(%24 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        spv.mlir.loop {
          spv.Branch ^bb1(%21 : i32)
        ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
          %23 = spv.SLessThan %22, %5 : i32
          spv.BranchConditional %23, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          spv.mlir.loop {
            spv.Branch ^bb1(%19 : i32)
          ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
            %26 = spv.SLessThan %25, %4 : i32
            spv.BranchConditional %26, ^bb2, ^bb3
          ^bb2:  // pred: ^bb1
            spv.mlir.loop {
              spv.Branch ^bb1(%6 : i32)
            ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
              %29 = spv.SLessThan %28, %1 : i32
              spv.BranchConditional %29, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              %30 = spv.IAdd %15, %22 : i32
              %31 = spv.IMul %30, %1 : i32
              %32 = spv.IAdd %28, %31 : i32
              %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
              %34 = spv.Load "StorageBuffer" %33 : f32
              %35 = spv.IAdd %16, %25 : i32
              %36 = spv.IMul %28, %2 : i32
              %37 = spv.IAdd %35, %36 : i32
              %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
              %39 = spv.Load "StorageBuffer" %38 : f32
              %40 = spv.IMul %30, %2 : i32
              %41 = spv.IAdd %35, %40 : i32
              %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
              %43 = spv.Load "StorageBuffer" %42 : f32
              %44 = spv.FMul %34, %39 : f32
              %45 = spv.FAdd %43, %44 : f32
              spv.Store "StorageBuffer" %42, %45 : f32
              %46 = spv.IAdd %28, %3 : i32
              spv.Branch ^bb1(%46 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            %27 = spv.IAdd %25, %4 : i32
            spv.Branch ^bb1(%27 : i32)
          ^bb3:  // pred: ^bb1
            spv.mlir.merge
          }
          %24 = spv.IAdd %22, %5 : i32
          spv.Branch ^bb1(%24 : i32)
        ^bb3:  // pred: ^bb1
          spv.mlir.merge
        }
        spv.Return
      }
      spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
      spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
    }
    hal.interface @io attributes {sym_visibility = "private"} {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::{anonymous}::ConvertToHALPass

{% raw %}
```
module  {
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
      ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
        %c4 = constant 4 : index
        %c4_0 = constant 4 : index
        %c1 = constant 1 : index
        hal.return %c4, %c4_0, %c1 : index, index, index
      }
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
          spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.func @dot_dispatch_0() "None" {
            %0 = spv.Constant 0.000000e+00 : f32
            %1 = spv.Constant 1024 : i32
            %2 = spv.Constant 64 : i32
            %3 = spv.Constant 1 : i32
            %4 = spv.Constant 16 : i32
            %5 = spv.Constant 8 : i32
            %6 = spv.Constant 0 : i32
            %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
            %11 = spv.Load "Input" %10 : vector<3xi32>
            %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
            %13 = spv.Load "Input" %10 : vector<3xi32>
            %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
            %15 = spv.IMul %14, %5 : i32
            %16 = spv.IMul %12, %4 : i32
            %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
            %18 = spv.Load "Input" %17 : vector<3xi32>
            %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
            %20 = spv.Load "Input" %17 : vector<3xi32>
            %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                %27 = spv.IAdd %15, %22 : i32
                %28 = spv.IAdd %16, %25 : i32
                %29 = spv.IMul %27, %2 : i32
                %30 = spv.IAdd %28, %29 : i32
                %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                spv.Store "StorageBuffer" %31, %0 : f32
                %32 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%32 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                spv.mlir.loop {
                  spv.Branch ^bb1(%6 : i32)
                ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
                  %29 = spv.SLessThan %28, %1 : i32
                  spv.BranchConditional %29, ^bb2, ^bb3
                ^bb2:  // pred: ^bb1
                  %30 = spv.IAdd %15, %22 : i32
                  %31 = spv.IMul %30, %1 : i32
                  %32 = spv.IAdd %28, %31 : i32
                  %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %34 = spv.Load "StorageBuffer" %33 : f32
                  %35 = spv.IAdd %16, %25 : i32
                  %36 = spv.IMul %28, %2 : i32
                  %37 = spv.IAdd %35, %36 : i32
                  %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %39 = spv.Load "StorageBuffer" %38 : f32
                  %40 = spv.IMul %30, %2 : i32
                  %41 = spv.IAdd %35, %40 : i32
                  %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %43 = spv.Load "StorageBuffer" %42 : f32
                  %44 = spv.FMul %34, %39 : f32
                  %45 = spv.FAdd %43, %44 : f32
                  spv.Store "StorageBuffer" %42, %45 : f32
                  %46 = spv.IAdd %28, %3 : i32
                  spv.Branch ^bb1(%46 : i32)
                ^bb3:  // pred: ^bb1
                  spv.mlir.merge
                }
                %27 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%27 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.Return
          }
          spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
          spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %c50331680_i32 = constant 50331680 : i32
    %c32 = constant 32 : index
    %c1024 = constant 1024 : index
    %sz = hal.allocator.compute_size<%allocator : !hal.allocator> shape([%c32, %c1024]) type(%c50331680_i32) : index
    %c64 = constant 64 : index
    %sz_0 = hal.allocator.compute_size<%allocator : !hal.allocator> shape([%c1024, %c64]) type(%c50331680_i32) : index
    %sz_1 = hal.allocator.compute_size<%allocator : !hal.allocator> shape([%c32, %c64]) type(%c50331680_i32) : index
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%sz_1}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %c64_2 = constant 64 : index
    %c32_3 = constant 32 : index
    %c1 = constant 1 : index
    %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
    %c0 = constant 0 : index
    %c1_4 = constant 1 : index
    %c2 = constant 2 : index
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %sz], 
      %c1_4 = (%arg1 : !hal.buffer)[%c0, %sz_0], 
      %c2 = (%buffer : !hal.buffer)[%c0, %sz_1]
    ])
    hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64_2 : index, %arg4 = %c32_3 : index, %arg5 = %c1 : index) {
      %c4 = constant 4 : index
      %c4_5 = constant 4 : index
      %c1_6 = constant 1 : index
      hal.command_buffer.dispatch.symbol<%arg2 : !hal.command_buffer> target(@dot_dispatch_0::@vulkan_spirv::@dot_dispatch_0) workgroups([%c4, %c4_5, %c1_6])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::Shape::{anonymous}::ExpandFunctionRankedShapeDimsPass

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %c50331680_i32 = constant 50331680 : i32
  %c32 = constant 32 : index
  %c1024 = constant 1024 : index
  %sz = hal.allocator.compute_size<%allocator : !hal.allocator> shape([%c32, %c1024]) type(%c50331680_i32) : index
  %c64 = constant 64 : index
  %sz_0 = hal.allocator.compute_size<%allocator : !hal.allocator> shape([%c1024, %c64]) type(%c50331680_i32) : index
  %sz_1 = hal.allocator.compute_size<%allocator : !hal.allocator> shape([%c32, %c64]) type(%c50331680_i32) : index
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%sz_1}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %c64_2 = constant 64 : index
  %c32_3 = constant 32 : index
  %c1 = constant 1 : index
  %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
  %c0 = constant 0 : index
  %c1_4 = constant 1 : index
  %c2 = constant 2 : index
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %sz], 
    %c1_4 = (%arg1 : !hal.buffer)[%c0, %sz_0], 
    %c2 = (%buffer : !hal.buffer)[%c0, %sz_1]
  ])
  hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64_2 : index, %arg4 = %c32_3 : index, %arg5 = %c1 : index) {
    %c4 = constant 4 : index
    %c4_5 = constant 4 : index
    %c1_6 = constant 1 : index
    hal.command_buffer.dispatch.symbol<%arg2 : !hal.command_buffer> target(@dot_dispatch_0::@vulkan_spirv::@dot_dispatch_0) workgroups([%c4, %c4_5, %c1_6])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c2 = constant 2 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
    %c4 = constant 4 : index
    %c1_0 = constant 1 : index
    hal.command_buffer.dispatch.symbol<%arg2 : !hal.command_buffer> target(@dot_dispatch_0::@vulkan_spirv::@dot_dispatch_0) workgroups([%c4, %c4, %c1_0])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c2 = constant 2 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
    %c4 = constant 4 : index
    %c1_0 = constant 1 : index
    hal.command_buffer.dispatch.symbol<%arg2 : !hal.command_buffer> target(@dot_dispatch_0::@vulkan_spirv::@dot_dispatch_0) workgroups([%c4, %c4, %c1_0])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::PackAllocationsPass

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {iree.module.export, iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c2 = constant 2 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
    %c4 = constant 4 : index
    %c1_0 = constant 1 : index
    hal.command_buffer.dispatch.symbol<%arg2 : !hal.command_buffer> target(@dot_dispatch_0::@vulkan_spirv::@dot_dispatch_0) workgroups([%c4, %c4, %c1_0])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::{anonymous}::PublicABIGenerationPass

{% raw %}
```
module  {
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
      ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
        %c4 = constant 4 : index
        %c4_0 = constant 4 : index
        %c1 = constant 1 : index
        hal.return %c4, %c4_0, %c1 : index, index, index
      }
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
          spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.func @dot_dispatch_0() "None" {
            %0 = spv.Constant 0.000000e+00 : f32
            %1 = spv.Constant 1024 : i32
            %2 = spv.Constant 64 : i32
            %3 = spv.Constant 1 : i32
            %4 = spv.Constant 16 : i32
            %5 = spv.Constant 8 : i32
            %6 = spv.Constant 0 : i32
            %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
            %11 = spv.Load "Input" %10 : vector<3xi32>
            %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
            %13 = spv.Load "Input" %10 : vector<3xi32>
            %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
            %15 = spv.IMul %14, %5 : i32
            %16 = spv.IMul %12, %4 : i32
            %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
            %18 = spv.Load "Input" %17 : vector<3xi32>
            %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
            %20 = spv.Load "Input" %17 : vector<3xi32>
            %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                %27 = spv.IAdd %15, %22 : i32
                %28 = spv.IAdd %16, %25 : i32
                %29 = spv.IMul %27, %2 : i32
                %30 = spv.IAdd %28, %29 : i32
                %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                spv.Store "StorageBuffer" %31, %0 : f32
                %32 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%32 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                spv.mlir.loop {
                  spv.Branch ^bb1(%6 : i32)
                ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
                  %29 = spv.SLessThan %28, %1 : i32
                  spv.BranchConditional %29, ^bb2, ^bb3
                ^bb2:  // pred: ^bb1
                  %30 = spv.IAdd %15, %22 : i32
                  %31 = spv.IMul %30, %1 : i32
                  %32 = spv.IAdd %28, %31 : i32
                  %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %34 = spv.Load "StorageBuffer" %33 : f32
                  %35 = spv.IAdd %16, %25 : i32
                  %36 = spv.IMul %28, %2 : i32
                  %37 = spv.IAdd %35, %36 : i32
                  %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %39 = spv.Load "StorageBuffer" %38 : f32
                  %40 = spv.IMul %30, %2 : i32
                  %41 = spv.IAdd %35, %40 : i32
                  %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %43 = spv.Load "StorageBuffer" %42 : f32
                  %44 = spv.FMul %34, %39 : f32
                  %45 = spv.FAdd %43, %44 : f32
                  spv.Store "StorageBuffer" %42, %45 : f32
                  %46 = spv.IAdd %28, %3 : i32
                  spv.Branch ^bb1(%46 : i32)
                ^bb3:  // pred: ^bb1
                  spv.mlir.merge
                }
                %27 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%27 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.Return
          }
          spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
          spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c2 = constant 2 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
      %c4 = constant 4 : index
      %c1_0 = constant 1 : index
      hal.command_buffer.dispatch.symbol<%arg2 : !hal.command_buffer> target(@dot_dispatch_0::@vulkan_spirv::@dot_dispatch_0) workgroups([%c4, %c4, %c1_0])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::LinkExecutablesPass

{% raw %}
```
module  {
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
      ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
        %c4 = constant 4 : index
        %c4_0 = constant 4 : index
        %c1 = constant 1 : index
        hal.return %c4, %c4_0, %c1 : index, index, index
      }
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
          spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.func @dot_dispatch_0() "None" {
            %0 = spv.Constant 0.000000e+00 : f32
            %1 = spv.Constant 1024 : i32
            %2 = spv.Constant 64 : i32
            %3 = spv.Constant 1 : i32
            %4 = spv.Constant 16 : i32
            %5 = spv.Constant 8 : i32
            %6 = spv.Constant 0 : i32
            %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
            %11 = spv.Load "Input" %10 : vector<3xi32>
            %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
            %13 = spv.Load "Input" %10 : vector<3xi32>
            %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
            %15 = spv.IMul %14, %5 : i32
            %16 = spv.IMul %12, %4 : i32
            %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
            %18 = spv.Load "Input" %17 : vector<3xi32>
            %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
            %20 = spv.Load "Input" %17 : vector<3xi32>
            %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                %27 = spv.IAdd %15, %22 : i32
                %28 = spv.IAdd %16, %25 : i32
                %29 = spv.IMul %27, %2 : i32
                %30 = spv.IAdd %28, %29 : i32
                %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                spv.Store "StorageBuffer" %31, %0 : f32
                %32 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%32 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                spv.mlir.loop {
                  spv.Branch ^bb1(%6 : i32)
                ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
                  %29 = spv.SLessThan %28, %1 : i32
                  spv.BranchConditional %29, ^bb2, ^bb3
                ^bb2:  // pred: ^bb1
                  %30 = spv.IAdd %15, %22 : i32
                  %31 = spv.IMul %30, %1 : i32
                  %32 = spv.IAdd %28, %31 : i32
                  %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %34 = spv.Load "StorageBuffer" %33 : f32
                  %35 = spv.IAdd %16, %25 : i32
                  %36 = spv.IMul %28, %2 : i32
                  %37 = spv.IAdd %35, %36 : i32
                  %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %39 = spv.Load "StorageBuffer" %38 : f32
                  %40 = spv.IMul %30, %2 : i32
                  %41 = spv.IAdd %35, %40 : i32
                  %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %43 = spv.Load "StorageBuffer" %42 : f32
                  %44 = spv.FMul %34, %39 : f32
                  %45 = spv.FAdd %43, %44 : f32
                  spv.Store "StorageBuffer" %42, %45 : f32
                  %46 = spv.IAdd %28, %3 : i32
                  spv.Branch ^bb1(%46 : i32)
                ^bb3:  // pred: ^bb1
                  spv.mlir.merge
                }
                %27 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%27 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.Return
          }
          spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
          spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c2 = constant 2 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
      %c4 = constant 4 : index
      %c1_0 = constant 1 : index
      hal.command_buffer.dispatch.symbol<%arg2 : !hal.command_buffer> target(@dot_dispatch_0::@vulkan_spirv::@dot_dispatch_0) workgroups([%c4, %c4, %c1_0])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::ResolveEntryPointOrdinalsPass

{% raw %}
```
module  {
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
      ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
        %c4 = constant 4 : index
        %c1 = constant 1 : index
        hal.return %c4, %c4, %c1 : index, index, index
      }
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
          spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.func @dot_dispatch_0() "None" {
            %0 = spv.Constant 0.000000e+00 : f32
            %1 = spv.Constant 1024 : i32
            %2 = spv.Constant 64 : i32
            %3 = spv.Constant 1 : i32
            %4 = spv.Constant 16 : i32
            %5 = spv.Constant 8 : i32
            %6 = spv.Constant 0 : i32
            %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
            %11 = spv.Load "Input" %10 : vector<3xi32>
            %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
            %13 = spv.Load "Input" %10 : vector<3xi32>
            %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
            %15 = spv.IMul %14, %5 : i32
            %16 = spv.IMul %12, %4 : i32
            %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
            %18 = spv.Load "Input" %17 : vector<3xi32>
            %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
            %20 = spv.Load "Input" %17 : vector<3xi32>
            %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                %27 = spv.IAdd %15, %22 : i32
                %28 = spv.IAdd %16, %25 : i32
                %29 = spv.IMul %27, %2 : i32
                %30 = spv.IAdd %28, %29 : i32
                %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                spv.Store "StorageBuffer" %31, %0 : f32
                %32 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%32 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                spv.mlir.loop {
                  spv.Branch ^bb1(%6 : i32)
                ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
                  %29 = spv.SLessThan %28, %1 : i32
                  spv.BranchConditional %29, ^bb2, ^bb3
                ^bb2:  // pred: ^bb1
                  %30 = spv.IAdd %15, %22 : i32
                  %31 = spv.IMul %30, %1 : i32
                  %32 = spv.IAdd %28, %31 : i32
                  %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %34 = spv.Load "StorageBuffer" %33 : f32
                  %35 = spv.IAdd %16, %25 : i32
                  %36 = spv.IMul %28, %2 : i32
                  %37 = spv.IAdd %35, %36 : i32
                  %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %39 = spv.Load "StorageBuffer" %38 : f32
                  %40 = spv.IMul %30, %2 : i32
                  %41 = spv.IAdd %35, %40 : i32
                  %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %43 = spv.Load "StorageBuffer" %42 : f32
                  %44 = spv.FMul %34, %39 : f32
                  %45 = spv.FAdd %43, %44 : f32
                  spv.Store "StorageBuffer" %42, %45 : f32
                  %46 = spv.IAdd %28, %3 : i32
                  spv.Branch ^bb1(%46 : i32)
                ^bb3:  // pred: ^bb1
                  spv.mlir.merge
                }
                %27 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%27 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.Return
          }
          spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
          spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c2 = constant 2 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
      %c4 = constant 4 : index
      %c1_0 = constant 1 : index
      %0 = hal.command_buffer.device<%arg2 : !hal.command_buffer> : !hal.device
      %exe = hal.executable.lookup device(%0 : !hal.device) executable(@dot_dispatch_0) : !hal.executable
      hal.command_buffer.dispatch<%arg2 : !hal.command_buffer> target(%exe : !hal.executable)[0] workgroups([%c4, %c4, %c1_0])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c2 = constant 2 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
    %c4 = constant 4 : index
    %c1_0 = constant 1 : index
    %0 = hal.command_buffer.device<%arg2 : !hal.command_buffer> : !hal.device
    %exe = hal.executable.lookup device(%0 : !hal.device) executable(@dot_dispatch_0) : !hal.executable
    hal.command_buffer.dispatch<%arg2 : !hal.command_buffer> target(%exe : !hal.executable)[0] workgroups([%c4, %c4, %c1_0])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c2 = constant 2 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %executable_layout = hal.executable_layout.lookup device(%device : !hal.device) layouts([[#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]]) : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%executable_layout : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
    %c4 = constant 4 : index
    %c1_0 = constant 1 : index
    %0 = hal.command_buffer.device<%arg2 : !hal.command_buffer> : !hal.device
    %exe = hal.executable.lookup device(%0 : !hal.device) executable(@dot_dispatch_0) : !hal.executable
    hal.command_buffer.dispatch<%arg2 : !hal.command_buffer> target(%exe : !hal.executable)[0] workgroups([%c4, %c4, %c1_0])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c50331680_i32 = constant 50331680 : i32
  %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
  hal.check_success %0, "semaphore wait failed"
  %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
  %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
  %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
  %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
  hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
  return %view : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c50331680_i32 = constant 50331680 : i32
  %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
  hal.check_success %0, "semaphore wait failed"
  %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
  %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
  %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
  %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
  hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
  return %view : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
  %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
  %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
  hal.check_success %1, "semaphore wait failed"
  return %0 : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
  %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
  %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
  hal.check_success %1, "semaphore wait failed"
  return %0 : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeResourceCachesPass

{% raw %}
```
module  {
  hal.variable @_descriptor_set_layout_0 init(@_descriptor_set_layout_0_initializer) : !hal.descriptor_set_layout attributes {sym_visibility = "private"}
  func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
    return %descriptor_set_layout : !hal.descriptor_set_layout
  }
  hal.variable @_executable_layout_0 init(@_executable_layout_0_initializer) : !hal.executable_layout attributes {sym_visibility = "private"}
  func private @_executable_layout_0_initializer() -> !hal.executable_layout {
    %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
    return %executable_layout : !hal.executable_layout
  }
  hal.variable @_executable_dot_dispatch_0 init(@_executable_dot_dispatch_0_initializer) : !hal.executable attributes {sym_visibility = "private"}
  func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.device.switch<%device : !hal.device> -> !hal.executable
    #hal.device.match.id<"vulkan*">(%arg0 = %device : !hal.device) {
      %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
      %exe = hal.executable.create device(%arg0 : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
      hal.return %exe : !hal.executable
    },
    #hal.match.always() {
      %1 = iree.null : !hal.executable
      hal.return %1 : !hal.executable
    }
    return %0 : !hal.executable
  }
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
      ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
        %c4 = constant 4 : index
        %c1 = constant 1 : index
        hal.return %c4, %c4, %c1 : index, index, index
      }
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
          spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.func @dot_dispatch_0() "None" {
            %0 = spv.Constant 0.000000e+00 : f32
            %1 = spv.Constant 1024 : i32
            %2 = spv.Constant 64 : i32
            %3 = spv.Constant 1 : i32
            %4 = spv.Constant 16 : i32
            %5 = spv.Constant 8 : i32
            %6 = spv.Constant 0 : i32
            %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
            %11 = spv.Load "Input" %10 : vector<3xi32>
            %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
            %13 = spv.Load "Input" %10 : vector<3xi32>
            %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
            %15 = spv.IMul %14, %5 : i32
            %16 = spv.IMul %12, %4 : i32
            %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
            %18 = spv.Load "Input" %17 : vector<3xi32>
            %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
            %20 = spv.Load "Input" %17 : vector<3xi32>
            %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                %27 = spv.IAdd %15, %22 : i32
                %28 = spv.IAdd %16, %25 : i32
                %29 = spv.IMul %27, %2 : i32
                %30 = spv.IAdd %28, %29 : i32
                %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                spv.Store "StorageBuffer" %31, %0 : f32
                %32 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%32 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                spv.mlir.loop {
                  spv.Branch ^bb1(%6 : i32)
                ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
                  %29 = spv.SLessThan %28, %1 : i32
                  spv.BranchConditional %29, ^bb2, ^bb3
                ^bb2:  // pred: ^bb1
                  %30 = spv.IAdd %15, %22 : i32
                  %31 = spv.IMul %30, %1 : i32
                  %32 = spv.IAdd %28, %31 : i32
                  %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %34 = spv.Load "StorageBuffer" %33 : f32
                  %35 = spv.IAdd %16, %25 : i32
                  %36 = spv.IMul %28, %2 : i32
                  %37 = spv.IAdd %35, %36 : i32
                  %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %39 = spv.Load "StorageBuffer" %38 : f32
                  %40 = spv.IMul %30, %2 : i32
                  %41 = spv.IAdd %35, %40 : i32
                  %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %43 = spv.Load "StorageBuffer" %42 : f32
                  %44 = spv.FMul %34, %39 : f32
                  %45 = spv.FAdd %43, %44 : f32
                  spv.Store "StorageBuffer" %42, %45 : f32
                  %46 = spv.IAdd %28, %3 : i32
                  spv.Branch ^bb1(%46 : i32)
                ^bb3:  // pred: ^bb1
                  spv.mlir.merge
                }
                %27 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%27 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.Return
          }
          spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
          spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c2 = constant 2 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    hal.device.switch<%device : !hal.device>
    #hal.device.match.id<"vulkan*">(%arg2 = %cmd : !hal.command_buffer, %arg3 = %c64 : index, %arg4 = %c32 : index, %arg5 = %c1 : index) {
      %c4 = constant 4 : index
      %c1_0 = constant 1 : index
      %1 = hal.command_buffer.device<%arg2 : !hal.command_buffer> : !hal.device
      %2 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%arg2 : !hal.command_buffer> target(%2 : !hal.executable)[0] workgroups([%c4, %c4, %c1_0])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass

{% raw %}
```
func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
  return %descriptor_set_layout : !hal.descriptor_set_layout
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass

{% raw %}
```
func private @_executable_layout_0_initializer() -> !hal.executable_layout {
  %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
  return %executable_layout : !hal.executable_layout
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass

{% raw %}
```
func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
  cond_br %0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
  br ^bb5(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %true = constant true
  cond_br %true, ^bb3, ^bb4
^bb3:  // pred: ^bb2
  %2 = iree.null : !hal.executable
  br ^bb5(%2 : !hal.executable)
^bb4:  // pred: ^bb2
  iree.unreachable "device not supported in the compiled configuration"
^bb5(%3: !hal.executable):  // 2 preds: ^bb1, ^bb3
  return %3 : !hal.executable
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c64 = constant 64 : index
  %c32 = constant 32 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %c2 = constant 2 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  %1 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
  cond_br %1, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %c4 = constant 4 : index
  %c1_0 = constant 1 : index
  %2 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
  %3 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%3 : !hal.executable)[0] workgroups([%c4, %c4, %c1_0])
  br ^bb3
^bb2:  // pred: ^bb0
  iree.unreachable "device not supported in the compiled configuration"
^bb3:  // pred: ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass

{% raw %}
```
func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c50331680_i32 = constant 50331680 : i32
  %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
  hal.check_success %0, "semaphore wait failed"
  %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
  %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
  %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
  %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
  hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
  return %view : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass

{% raw %}
```
func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
  %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
  %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
  hal.check_success %1, "semaphore wait failed"
  return %0 : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After ConvertAffineToStandard

{% raw %}
```
module  {
  hal.variable @_descriptor_set_layout_0 init(@_descriptor_set_layout_0_initializer) : !hal.descriptor_set_layout attributes {sym_visibility = "private"}
  func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
    return %descriptor_set_layout : !hal.descriptor_set_layout
  }
  hal.variable @_executable_layout_0 init(@_executable_layout_0_initializer) : !hal.executable_layout attributes {sym_visibility = "private"}
  func private @_executable_layout_0_initializer() -> !hal.executable_layout {
    %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
    return %executable_layout : !hal.executable_layout
  }
  hal.variable @_executable_dot_dispatch_0 init(@_executable_dot_dispatch_0_initializer) : !hal.executable attributes {sym_visibility = "private"}
  func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
    cond_br %0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
    br ^bb5(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %true = constant true
    cond_br %true, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %2 = iree.null : !hal.executable
    br ^bb5(%2 : !hal.executable)
  ^bb4:  // pred: ^bb2
    iree.unreachable "device not supported in the compiled configuration"
  ^bb5(%3: !hal.executable):  // 2 preds: ^bb1, ^bb3
    return %3 : !hal.executable
  }
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
      ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
        %c4 = constant 4 : index
        %c1 = constant 1 : index
        hal.return %c4, %c4, %c1 : index, index, index
      }
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
          spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.func @dot_dispatch_0() "None" {
            %0 = spv.Constant 0.000000e+00 : f32
            %1 = spv.Constant 1024 : i32
            %2 = spv.Constant 64 : i32
            %3 = spv.Constant 1 : i32
            %4 = spv.Constant 16 : i32
            %5 = spv.Constant 8 : i32
            %6 = spv.Constant 0 : i32
            %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
            %11 = spv.Load "Input" %10 : vector<3xi32>
            %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
            %13 = spv.Load "Input" %10 : vector<3xi32>
            %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
            %15 = spv.IMul %14, %5 : i32
            %16 = spv.IMul %12, %4 : i32
            %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
            %18 = spv.Load "Input" %17 : vector<3xi32>
            %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
            %20 = spv.Load "Input" %17 : vector<3xi32>
            %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                %27 = spv.IAdd %15, %22 : i32
                %28 = spv.IAdd %16, %25 : i32
                %29 = spv.IMul %27, %2 : i32
                %30 = spv.IAdd %28, %29 : i32
                %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                spv.Store "StorageBuffer" %31, %0 : f32
                %32 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%32 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                spv.mlir.loop {
                  spv.Branch ^bb1(%6 : i32)
                ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
                  %29 = spv.SLessThan %28, %1 : i32
                  spv.BranchConditional %29, ^bb2, ^bb3
                ^bb2:  // pred: ^bb1
                  %30 = spv.IAdd %15, %22 : i32
                  %31 = spv.IMul %30, %1 : i32
                  %32 = spv.IAdd %28, %31 : i32
                  %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %34 = spv.Load "StorageBuffer" %33 : f32
                  %35 = spv.IAdd %16, %25 : i32
                  %36 = spv.IMul %28, %2 : i32
                  %37 = spv.IAdd %35, %36 : i32
                  %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %39 = spv.Load "StorageBuffer" %38 : f32
                  %40 = spv.IMul %30, %2 : i32
                  %41 = spv.IAdd %35, %40 : i32
                  %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %43 = spv.Load "StorageBuffer" %42 : f32
                  %44 = spv.FMul %34, %39 : f32
                  %45 = spv.FAdd %43, %44 : f32
                  spv.Store "StorageBuffer" %42, %45 : f32
                  %46 = spv.IAdd %28, %3 : i32
                  spv.Branch ^bb1(%46 : i32)
                ^bb3:  // pred: ^bb1
                  spv.mlir.merge
                }
                %27 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%27 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.Return
          }
          spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
          spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c2 = constant 2 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    %1 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
    cond_br %1, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %c4 = constant 4 : index
    %c1_0 = constant 1 : index
    %2 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %3 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%3 : !hal.executable)[0] workgroups([%c4, %c4, %c1_0])
    br ^bb3
  ^bb2:  // pred: ^bb0
    iree.unreachable "device not supported in the compiled configuration"
  ^bb3:  // pred: ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::MemoizeDeviceQueriesPass

{% raw %}
```
module  {
  hal.variable @_device_match_id_0 init(@_device_match_id_0_initializer) : i1 attributes {sym_visibility = "private"}
  func private @_device_match_id_0_initializer() -> i1 {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
    return %0 : i1
  }
  hal.variable @_descriptor_set_layout_0 init(@_descriptor_set_layout_0_initializer) : !hal.descriptor_set_layout attributes {sym_visibility = "private"}
  func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
    return %descriptor_set_layout : !hal.descriptor_set_layout
  }
  hal.variable @_executable_layout_0 init(@_executable_layout_0_initializer) : !hal.executable_layout attributes {sym_visibility = "private"}
  func private @_executable_layout_0_initializer() -> !hal.executable_layout {
    %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
    return %executable_layout : !hal.executable_layout
  }
  hal.variable @_executable_dot_dispatch_0 init(@_executable_dot_dispatch_0_initializer) : !hal.executable attributes {sym_visibility = "private"}
  func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.variable.load @_device_match_id_0 : i1
    cond_br %0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
    br ^bb5(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %true = constant true
    cond_br %true, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %2 = iree.null : !hal.executable
    br ^bb5(%2 : !hal.executable)
  ^bb4:  // pred: ^bb2
    iree.unreachable "device not supported in the compiled configuration"
  ^bb5(%3: !hal.executable):  // 2 preds: ^bb1, ^bb3
    return %3 : !hal.executable
  }
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.target @vulkan_spirv, filter="vulkan*" {
      hal.executable.entry_point @dot_dispatch_0 attributes {interface = @io, ordinal = 0 : index, signature = (!flow.dispatch.tensor<readonly:32x1024xf32>, !flow.dispatch.tensor<readonly:1024x64xf32>, !flow.dispatch.tensor<writeonly:32x64xf32>) -> ()} {
      ^bb0(%arg0: index, %arg1: index, %arg2: index):  // no predecessors
        %c4 = constant 4 : index
        %c1 = constant 1 : index
        hal.return %c4, %c4, %c1 : index, index, index
      }
      module attributes {spv.target_env = #spv.target_env<#spv.vce<v1.3, [Shader, GroupNonUniform, GroupNonUniformVote, GroupNonUniformArithmetic, GroupNonUniformBallot, GroupNonUniformShuffle, GroupNonUniformShuffleRelative], [SPV_KHR_storage_buffer_storage_class]>, SwiftShader:CPU, {cooperative_matrix_properties_nv = [], max_compute_shared_memory_size = 16384 : i32, max_compute_workgroup_invocations = 128 : i32, max_compute_workgroup_size = dense<[128, 128, 64]> : vector<3xi32>, subgroup_size = 4 : i32}>}  {
        spv.module Logical GLSL450 requires #spv.vce<v1.0, [Shader], [SPV_KHR_storage_buffer_storage_class]> {
          spv.GlobalVariable @__builtin_var_LocalInvocationId__ built_in("LocalInvocationId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__builtin_var_WorkgroupId__ built_in("WorkgroupId") : !spv.ptr<vector<3xi32>, Input>
          spv.GlobalVariable @__resource_var_94857743815344__ bind(0, 2) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742342896__ bind(0, 1) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.GlobalVariable @__resource_var_94857742610816__ bind(0, 0) : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
          spv.func @dot_dispatch_0() "None" {
            %0 = spv.Constant 0.000000e+00 : f32
            %1 = spv.Constant 1024 : i32
            %2 = spv.Constant 64 : i32
            %3 = spv.Constant 1 : i32
            %4 = spv.Constant 16 : i32
            %5 = spv.Constant 8 : i32
            %6 = spv.Constant 0 : i32
            %7 = spv.mlir.addressof @__resource_var_94857742610816__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %8 = spv.mlir.addressof @__resource_var_94857742342896__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %9 = spv.mlir.addressof @__resource_var_94857743815344__ : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>
            %10 = spv.mlir.addressof @__builtin_var_WorkgroupId__ : !spv.ptr<vector<3xi32>, Input>
            %11 = spv.Load "Input" %10 : vector<3xi32>
            %12 = spv.CompositeExtract %11[0 : i32] : vector<3xi32>
            %13 = spv.Load "Input" %10 : vector<3xi32>
            %14 = spv.CompositeExtract %13[1 : i32] : vector<3xi32>
            %15 = spv.IMul %14, %5 : i32
            %16 = spv.IMul %12, %4 : i32
            %17 = spv.mlir.addressof @__builtin_var_LocalInvocationId__ : !spv.ptr<vector<3xi32>, Input>
            %18 = spv.Load "Input" %17 : vector<3xi32>
            %19 = spv.CompositeExtract %18[0 : i32] : vector<3xi32>
            %20 = spv.Load "Input" %17 : vector<3xi32>
            %21 = spv.CompositeExtract %20[1 : i32] : vector<3xi32>
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                %27 = spv.IAdd %15, %22 : i32
                %28 = spv.IAdd %16, %25 : i32
                %29 = spv.IMul %27, %2 : i32
                %30 = spv.IAdd %28, %29 : i32
                %31 = spv.AccessChain %9[%6, %30] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                spv.Store "StorageBuffer" %31, %0 : f32
                %32 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%32 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.mlir.loop {
              spv.Branch ^bb1(%21 : i32)
            ^bb1(%22: i32):  // 2 preds: ^bb0, ^bb2
              %23 = spv.SLessThan %22, %5 : i32
              spv.BranchConditional %23, ^bb2, ^bb3
            ^bb2:  // pred: ^bb1
              spv.mlir.loop {
                spv.Branch ^bb1(%19 : i32)
              ^bb1(%25: i32):  // 2 preds: ^bb0, ^bb2
                %26 = spv.SLessThan %25, %4 : i32
                spv.BranchConditional %26, ^bb2, ^bb3
              ^bb2:  // pred: ^bb1
                spv.mlir.loop {
                  spv.Branch ^bb1(%6 : i32)
                ^bb1(%28: i32):  // 2 preds: ^bb0, ^bb2
                  %29 = spv.SLessThan %28, %1 : i32
                  spv.BranchConditional %29, ^bb2, ^bb3
                ^bb2:  // pred: ^bb1
                  %30 = spv.IAdd %15, %22 : i32
                  %31 = spv.IMul %30, %1 : i32
                  %32 = spv.IAdd %28, %31 : i32
                  %33 = spv.AccessChain %7[%6, %32] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %34 = spv.Load "StorageBuffer" %33 : f32
                  %35 = spv.IAdd %16, %25 : i32
                  %36 = spv.IMul %28, %2 : i32
                  %37 = spv.IAdd %35, %36 : i32
                  %38 = spv.AccessChain %8[%6, %37] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %39 = spv.Load "StorageBuffer" %38 : f32
                  %40 = spv.IMul %30, %2 : i32
                  %41 = spv.IAdd %35, %40 : i32
                  %42 = spv.AccessChain %9[%6, %41] : !spv.ptr<!spv.struct<(!spv.rtarray<f32, stride=4> [0])>, StorageBuffer>, i32, i32
                  %43 = spv.Load "StorageBuffer" %42 : f32
                  %44 = spv.FMul %34, %39 : f32
                  %45 = spv.FAdd %43, %44 : f32
                  spv.Store "StorageBuffer" %42, %45 : f32
                  %46 = spv.IAdd %28, %3 : i32
                  spv.Branch ^bb1(%46 : i32)
                ^bb3:  // pred: ^bb1
                  spv.mlir.merge
                }
                %27 = spv.IAdd %25, %4 : i32
                spv.Branch ^bb1(%27 : i32)
              ^bb3:  // pred: ^bb1
                spv.mlir.merge
              }
              %24 = spv.IAdd %22, %5 : i32
              spv.Branch ^bb1(%24 : i32)
            ^bb3:  // pred: ^bb1
              spv.mlir.merge
            }
            spv.Return
          }
          spv.EntryPoint "GLCompute" @dot_dispatch_0, @__builtin_var_WorkgroupId__, @__builtin_var_LocalInvocationId__
          spv.ExecutionMode @dot_dispatch_0 "LocalSize", 16, 8, 1
        }
        hal.interface @io attributes {sym_visibility = "private"} {
          hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
          hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
        }
      }
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c64 = constant 64 : index
    %c32 = constant 32 : index
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %c2 = constant 2 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    %1 = hal.variable.load @_device_match_id_0 : i1
    cond_br %1, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %c4 = constant 4 : index
    %c1_0 = constant 1 : index
    %2 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %3 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%3 : !hal.executable)[0] workgroups([%c4, %c4, %c1_0])
    br ^bb3
  ^bb2:  // pred: ^bb0
    iree.unreachable "device not supported in the compiled configuration"
  ^bb3:  // pred: ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_device_match_id_0_initializer() -> i1 {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
  return %0 : i1
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func private @_device_match_id_0_initializer() -> i1 {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
  return %0 : i1
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::CSEVariableLoadsPass

{% raw %}
```
func private @_device_match_id_0_initializer() -> i1 {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
  return %0 : i1
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
  return %descriptor_set_layout : !hal.descriptor_set_layout
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
  return %descriptor_set_layout : !hal.descriptor_set_layout
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::CSEVariableLoadsPass

{% raw %}
```
func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
  return %descriptor_set_layout : !hal.descriptor_set_layout
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_executable_layout_0_initializer() -> !hal.executable_layout {
  %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
  return %executable_layout : !hal.executable_layout
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func private @_executable_layout_0_initializer() -> !hal.executable_layout {
  %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
  return %executable_layout : !hal.executable_layout
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::CSEVariableLoadsPass

{% raw %}
```
func private @_executable_layout_0_initializer() -> !hal.executable_layout {
  %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
  return %executable_layout : !hal.executable_layout
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.variable.load @_device_match_id_0 : i1
  cond_br %0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
  br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = iree.null : !hal.executable
  br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  return %3 : !hal.executable
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.variable.load @_device_match_id_0 : i1
  cond_br %0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
  br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = iree.null : !hal.executable
  br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  return %3 : !hal.executable
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::CSEVariableLoadsPass

{% raw %}
```
func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.variable.load @_device_match_id_0 : i1
  cond_br %0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
  br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = iree.null : !hal.executable
  br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  return %3 : !hal.executable
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::SerializeExecutablesPass

{% raw %}
```
hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
  hal.interface @io {
    hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
    hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
  }
  hal.executable.binary @vulkan_spirv attributes {data = opaque<"_", "0xDEADBEEF"> : vector<2332xi8>, format = "SPVE"} {
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c0 = constant 0 : index
  %c2 = constant 2 : index
  %c4 = constant 4 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  %1 = hal.variable.load @_device_match_id_0 : i1
  cond_br %1, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %2 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%2 : !hal.executable)[0] workgroups([%c4, %c4, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
^bb2:  // pred: ^bb0
  iree.unreachable "device not supported in the compiled configuration"
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c0 = constant 0 : index
  %c2 = constant 2 : index
  %c4 = constant 4 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  %1 = hal.variable.load @_device_match_id_0 : i1
  cond_br %1, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %2 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%2 : !hal.executable)[0] workgroups([%c4, %c4, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
^bb2:  // pred: ^bb0
  iree.unreachable "device not supported in the compiled configuration"
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::CSEVariableLoadsPass

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c0 = constant 0 : index
  %c2 = constant 2 : index
  %c4 = constant 4 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  %1 = hal.variable.load @_device_match_id_0 : i1
  cond_br %1, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %2 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%2 : !hal.executable)[0] workgroups([%c4, %c4, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
^bb2:  // pred: ^bb0
  iree.unreachable "device not supported in the compiled configuration"
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c50331680_i32 = constant 50331680 : i32
  %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
  hal.check_success %0, "semaphore wait failed"
  %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
  %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
  %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
  %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
  hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
  return %view : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c50331680_i32 = constant 50331680 : i32
  %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
  hal.check_success %0, "semaphore wait failed"
  %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
  %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
  %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
  %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
  hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
  return %view : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::CSEVariableLoadsPass

{% raw %}
```
func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c50331680_i32 = constant 50331680 : i32
  %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
  hal.check_success %0, "semaphore wait failed"
  %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
  %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
  %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
  %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
  hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
  return %view : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
  %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
  %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
  hal.check_success %1, "semaphore wait failed"
  return %0 : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
  %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
  %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
  hal.check_success %1, "semaphore wait failed"
  return %0 : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::HAL::CSEVariableLoadsPass

{% raw %}
```
func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
  %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
  %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
  hal.check_success %1, "semaphore wait failed"
  return %0 : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After SymbolDCE

{% raw %}
```
module  {
  hal.variable @_device_match_id_0 init(@_device_match_id_0_initializer) : i1 attributes {sym_visibility = "private"}
  func private @_device_match_id_0_initializer() -> i1 {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
    return %0 : i1
  }
  hal.variable @_descriptor_set_layout_0 init(@_descriptor_set_layout_0_initializer) : !hal.descriptor_set_layout attributes {sym_visibility = "private"}
  func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
    return %descriptor_set_layout : !hal.descriptor_set_layout
  }
  hal.variable @_executable_layout_0 init(@_executable_layout_0_initializer) : !hal.executable_layout attributes {sym_visibility = "private"}
  func private @_executable_layout_0_initializer() -> !hal.executable_layout {
    %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
    return %executable_layout : !hal.executable_layout
  }
  hal.variable @_executable_dot_dispatch_0 init(@_executable_dot_dispatch_0_initializer) : !hal.executable attributes {sym_visibility = "private"}
  func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.variable.load @_device_match_id_0 : i1
    cond_br %0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
    br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = iree.null : !hal.executable
    br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    return %3 : !hal.executable
  }
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.binary @vulkan_spirv attributes {data = opaque<"_", "0xDEADBEEF"> : vector<2332xi8>, format = "SPVE"} {
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c0 = constant 0 : index
    %c2 = constant 2 : index
    %c4 = constant 4 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    %1 = hal.variable.load @_device_match_id_0 : i1
    cond_br %1, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %2 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%2 : !hal.executable)[0] workgroups([%c4, %c4, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  ^bb2:  // pred: ^bb0
    iree.unreachable "device not supported in the compiled configuration"
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_device_match_id_0_initializer() -> i1 {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
  return %0 : i1
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
  return %descriptor_set_layout : !hal.descriptor_set_layout
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_executable_layout_0_initializer() -> !hal.executable_layout {
  %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
  return %executable_layout : !hal.executable_layout
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
  %device = hal.ex.shared_device : !hal.device
  %0 = hal.variable.load @_device_match_id_0 : i1
  cond_br %0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
  br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = iree.null : !hal.executable
  br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  return %3 : !hal.executable
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
  %c131072 = constant 131072 : index
  %c262144 = constant 262144 : index
  %c8192 = constant 8192 : index
  %c0 = constant 0 : index
  %c2 = constant 2 : index
  %c4 = constant 4 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
  hal.command_buffer.begin<%cmd : !hal.command_buffer>
  %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
    %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
    %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
  ])
  %1 = hal.variable.load @_device_match_id_0 : i1
  cond_br %1, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %2 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%2 : !hal.executable)[0] workgroups([%c4, %c4, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
  hal.command_buffer.end<%cmd : !hal.command_buffer>
  hal.ex.submit_and_wait %device, %cmd
  return %buffer : !hal.buffer
^bb2:  // pred: ^bb0
  iree.unreachable "device not supported in the compiled configuration"
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
  %c32 = constant 32 : index
  %c64 = constant 64 : index
  %c50331680_i32 = constant 50331680 : i32
  %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
  hal.check_success %0, "semaphore wait failed"
  %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
  %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
  %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
  %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
  hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
  return %view : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  %device = hal.ex.shared_device : !hal.device
  %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
  %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
  %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
  hal.check_success %1, "semaphore wait failed"
  return %0 : !hal.buffer_view
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
module  {
  hal.variable @_device_match_id_0 init(@_device_match_id_0_initializer) : i1 attributes {sym_visibility = "private"}
  func private @_device_match_id_0_initializer() -> i1 {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.device.match.id<%device : !hal.device> pattern("vulkan*") : i1
    return %0 : i1
  }
  hal.variable @_descriptor_set_layout_0 init(@_descriptor_set_layout_0_initializer) : !hal.descriptor_set_layout attributes {sym_visibility = "private"}
  func private @_descriptor_set_layout_0_initializer() -> !hal.descriptor_set_layout {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) usage(PushOnly) bindings([#hal.descriptor_set_layout_binding<0, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<1, "StorageBuffer", R>, #hal.descriptor_set_layout_binding<2, "StorageBuffer", DW>]) : !hal.descriptor_set_layout
    return %descriptor_set_layout : !hal.descriptor_set_layout
  }
  hal.variable @_executable_layout_0 init(@_executable_layout_0_initializer) : !hal.executable_layout attributes {sym_visibility = "private"}
  func private @_executable_layout_0_initializer() -> !hal.executable_layout {
    %0 = hal.variable.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %executable_layout = hal.executable_layout.create device(%device : !hal.device) push_constants(0) layouts([%0]) : !hal.executable_layout
    return %executable_layout : !hal.executable_layout
  }
  hal.variable @_executable_dot_dispatch_0 init(@_executable_dot_dispatch_0_initializer) : !hal.executable attributes {sym_visibility = "private"}
  func private @_executable_dot_dispatch_0_initializer() -> !hal.executable {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.variable.load @_device_match_id_0 : i1
    cond_br %0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %1 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@dot_dispatch_0::@vulkan_spirv) layouts([%1]) : !hal.executable
    br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = iree.null : !hal.executable
    br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    return %3 : !hal.executable
  }
  hal.executable @dot_dispatch_0 attributes {sym_visibility = "private"} {
    hal.interface @io {
      hal.interface.binding @s0b0_ro_external, set=0, binding=0, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b1_ro_external, set=0, binding=1, type="StorageBuffer", access="Read"
      hal.interface.binding @s0b2_xw_external, set=0, binding=2, type="StorageBuffer", access="Write|Discard"
    }
    hal.executable.binary @vulkan_spirv attributes {data = opaque<"_", "0xDEADBEEF"> : vector<2332xi8>, format = "SPVE"} {
    }
  }
  func @dot(%arg0: !hal.buffer, %arg1: !hal.buffer) -> !hal.buffer attributes {noinline} {
    %c131072 = constant 131072 : index
    %c262144 = constant 262144 : index
    %c8192 = constant 8192 : index
    %c0 = constant 0 : index
    %c2 = constant 2 : index
    %c4 = constant 4 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> type("HostVisible|DeviceVisible|DeviceLocal") usage("Transfer|Mapping|Dispatch") : !hal.buffer{%c8192}
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    hal.command_buffer.begin<%cmd : !hal.command_buffer>
    %0 = hal.variable.load @_executable_layout_0 : !hal.executable_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%0 : !hal.executable_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %c131072], 
      %c1 = (%arg1 : !hal.buffer)[%c0, %c262144], 
      %c2 = (%buffer : !hal.buffer)[%c0, %c8192]
    ])
    %1 = hal.variable.load @_device_match_id_0 : i1
    cond_br %1, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %2 = hal.variable.load @_executable_dot_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%2 : !hal.executable)[0] workgroups([%c4, %c4, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|CommandRetire") target("CommandIssue|Dispatch") flags("None")
    hal.command_buffer.end<%cmd : !hal.command_buffer>
    hal.ex.submit_and_wait %device, %cmd
    return %buffer : !hal.buffer
  ^bb2:  // pred: ^bb0
    iree.unreachable "device not supported in the compiled configuration"
  }
  func @dot$async(%arg0: !hal.semaphore, %arg1: index, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.semaphore, %arg5: index) -> !hal.buffer_view attributes {iree.module.export = "dot$async"} {
    %c32 = constant 32 : index
    %c64 = constant 64 : index
    %c50331680_i32 = constant 50331680 : i32
    %0 = hal.semaphore.await<%arg0 : !hal.semaphore> until(%arg1) : i32
    hal.check_success %0, "semaphore wait failed"
    %buffer = hal.buffer_view.buffer %arg2 : !hal.buffer
    %buffer_0 = hal.buffer_view.buffer %arg3 : !hal.buffer
    %1 = call @dot(%buffer, %buffer_0) : (!hal.buffer, !hal.buffer) -> !hal.buffer
    %view = hal.buffer_view.create %1, element_type = %c50331680_i32, shape = [%c32, %c64] : !hal.buffer -> !hal.buffer_view
    hal.semaphore.signal<%arg4 : !hal.semaphore> value(%arg5)
    return %view : !hal.buffer_view
  }
  func @dot$sync(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.module.export = "dot", iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %c0 = constant 0 : index
    %c1 = constant 1 : index
    %device = hal.ex.shared_device : !hal.device
    %semaphore = hal.semaphore.create device(%device : !hal.device) initial(%c0) : !hal.semaphore
    %0 = call @dot$async(%semaphore, %c0, %arg0, %arg1, %semaphore, %c1) : (!hal.semaphore, index, !hal.buffer_view, !hal.buffer_view, !hal.semaphore, index) -> !hal.buffer_view
    %1 = hal.semaphore.await<%semaphore : !hal.semaphore> until(%c1) : i32
    hal.check_success %1, "semaphore wait failed"
    return %0 : !hal.buffer_view
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::VM::ConversionPass

{% raw %}
```
module  {
  vm.module @module {
    vm.global.i32 @_device_match_id_0 init(@_device_match_id_0_initializer) : i32
    vm.func private @_device_match_id_0_initializer() -> i32 {
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.rodata.inline "_utf8_vulkan_7197BF52A22CAFD7" {alignment = 1 : i64} : !vm.ref<!iree.byte_buffer> = dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
      %0 = vm.call @hal.device.match.id(%ref, %ref_0) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
      vm.return %0 : i32
    }
    vm.global.ref @_descriptor_set_layout_0 init(@_descriptor_set_layout_0_initializer) : !vm.ref<!hal.descriptor_set_layout>
    vm.func private @_descriptor_set_layout_0_initializer() -> !vm.ref<!hal.descriptor_set_layout> {
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %c1 = vm.const.i32 1 : i32
      %zero = vm.const.i32.zero : i32
      %c7 = vm.const.i32 7 : i32
      %c1_0 = vm.const.i32 1 : i32
      %c1_1 = vm.const.i32 1 : i32
      %c7_2 = vm.const.i32 7 : i32
      %c1_3 = vm.const.i32 1 : i32
      %c2 = vm.const.i32 2 : i32
      %c7_4 = vm.const.i32 7 : i32
      %c6 = vm.const.i32 6 : i32
      %ref_5 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %c1, [(%zero, %c7, %c1_0), (%c1_1, %c7_2, %c1_3), (%c2, %c7_4, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      vm.return %ref_5 : !vm.ref<!hal.descriptor_set_layout>
    }
    vm.global.ref @_executable_layout_0 init(@_executable_layout_0_initializer) : !vm.ref<!hal.executable_layout>
    vm.func private @_executable_layout_0_initializer() -> !vm.ref<!hal.executable_layout> {
      %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %zero = vm.const.i32.zero : i32
      %ref_0 = vm.call.variadic @hal.executable_layout.create(%ref, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
      vm.return %ref_0 : !vm.ref<!hal.executable_layout>
    }
    vm.global.ref @_executable_dot_dispatch_0 init(@_executable_dot_dispatch_0_initializer) : !vm.ref<!hal.executable>
    vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
    vm.func private @_executable_dot_dispatch_0_initializer() -> !vm.ref<!hal.executable> {
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %ref_0 = vm.rodata.inline "_utf8_spve_9EB892746B9D70D0" {alignment = 1 : i64} : !vm.ref<!iree.byte_buffer> = dense<[83, 80, 86, 69]> : vector<4xi8>
      %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
      %ref_1 = vm.call.variadic @hal.executable.create(%ref, %ref_0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_1 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%0: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.return %0 : !vm.ref<!hal.executable>
    }
    vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
      %c131072 = vm.const.i32 131072 : i32
      %c262144 = vm.const.i32 262144 : i32
      %c8192 = vm.const.i32 8192 : i32
      %zero = vm.const.i32.zero : i32
      %c2 = vm.const.i32 2 : i32
      %c4 = vm.const.i32 4 : i32
      %c1 = vm.const.i32 1 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %c50 = vm.const.i32 50 : i32
      %c14 = vm.const.i32 14 : i32
      %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
      %c1_2 = vm.const.i32 1 : i32
      %c3 = vm.const.i32 3 : i32
      %ref_3 = vm.call @hal.command_buffer.create(%ref, %c1_2, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.call @hal.command_buffer.begin(%ref_3) : (!vm.ref<!hal.command_buffer>) -> ()
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_3, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      %zero_4 = vm.const.i32.zero : i32
      vm.call @hal.command_buffer.dispatch(%ref_3, %_executable_dot_dispatch_0, %zero_4, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      %c20 = vm.const.i32 20 : i32
      %c5 = vm.const.i32 5 : i32
      %zero_5 = vm.const.i32.zero : i32
      vm.call @hal.command_buffer.execution_barrier(%ref_3, %c20, %c5, %zero_5) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.end(%ref_3) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.call @hal.ex.submit_and_wait(%ref, %ref_3) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref_1 : !vm.ref<!hal.buffer>
    ^bb2:  // pred: ^bb0
      %c2_6 = vm.const.i32 2 : i32
      vm.fail %c2_6, "device not supported in the compiled configuration"
    }
    vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_fail %0, "semaphore wait failed"
      %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
      vm.return %ref_2 : !vm.ref<!hal.buffer_view>
    }
    vm.export @dot$async
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.wrap.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.ref<!iree.byte_buffer>, %offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.allocator(%buffer : !vm.ref<!hal.buffer>) -> !vm.ref<!hal.allocator> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.byte_length(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.ref<!iree.byte_buffer>, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32, %pattern : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.bind_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %descriptor_set : !vm.ref<!hal.descriptor_set>, %dynamic_offsets : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set.create(%device : !vm.ref<!hal.device>, %set_layout : !vm.ref<!hal.descriptor_set_layout>, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) -> !vm.ref<!hal.descriptor_set> attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i32(%device : !vm.ref<!hal.device>, %key : !vm.ref<!iree.byte_buffer>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.query(%semaphore : !vm.ref<!hal.semaphore>) -> (i32, i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.fail(%semaphore : !vm.ref<!hal.semaphore>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
    vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
      %zero = vm.const.i32.zero : i32
      %c1 = vm.const.i32 1 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
      %ref_1 = vm.call @dot$async(%ref_0, %zero, %arg0, %arg1, %ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.semaphore>, i32) -> !vm.ref<!hal.buffer_view>
      %0 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_fail %0, "semaphore wait failed"
      vm.return %ref_1 : !vm.ref<!hal.buffer_view>
    }
    vm.export @dot$sync as("dot")
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::VM::HoistInlinedRodataPass

{% raw %}
```
vm.module @module {
  vm.global.i32 @_device_match_id_0 init(@_device_match_id_0_initializer) : i32
  vm.rodata @_utf8_vulkan_7197BF52A22CAFD7 dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
  vm.func private @_device_match_id_0_initializer() -> i32 {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
    %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
    vm.return %0 : i32
  }
  vm.global.ref @_descriptor_set_layout_0 init(@_descriptor_set_layout_0_initializer) : !vm.ref<!hal.descriptor_set_layout>
  vm.func private @_descriptor_set_layout_0_initializer() -> !vm.ref<!hal.descriptor_set_layout> {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %c1 = vm.const.i32 1 : i32
    %zero = vm.const.i32.zero : i32
    %c7 = vm.const.i32 7 : i32
    %c1_0 = vm.const.i32 1 : i32
    %c1_1 = vm.const.i32 1 : i32
    %c7_2 = vm.const.i32 7 : i32
    %c1_3 = vm.const.i32 1 : i32
    %c2 = vm.const.i32 2 : i32
    %c7_4 = vm.const.i32 7 : i32
    %c6 = vm.const.i32 6 : i32
    %ref_5 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %c1, [(%zero, %c7, %c1_0), (%c1_1, %c7_2, %c1_3), (%c2, %c7_4, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    vm.return %ref_5 : !vm.ref<!hal.descriptor_set_layout>
  }
  vm.global.ref @_executable_layout_0 init(@_executable_layout_0_initializer) : !vm.ref<!hal.executable_layout>
  vm.func private @_executable_layout_0_initializer() -> !vm.ref<!hal.executable_layout> {
    %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %zero = vm.const.i32.zero : i32
    %ref_0 = vm.call.variadic @hal.executable_layout.create(%ref, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
    vm.return %ref_0 : !vm.ref<!hal.executable_layout>
  }
  vm.global.ref @_executable_dot_dispatch_0 init(@_executable_dot_dispatch_0_initializer) : !vm.ref<!hal.executable>
  vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
  vm.rodata @_utf8_spve_9EB892746B9D70D0 dense<[83, 80, 86, 69]> : vector<4xi8>
  vm.func private @_executable_dot_dispatch_0_initializer() -> !vm.ref<!hal.executable> {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
    vm.cond_br %_device_match_id_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
    %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
    %ref_0 = vm.call.variadic @hal.executable.create(%ref, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_0 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%0: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.return %0 : !vm.ref<!hal.executable>
  }
  vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
    %c131072 = vm.const.i32 131072 : i32
    %c262144 = vm.const.i32 262144 : i32
    %c8192 = vm.const.i32 8192 : i32
    %zero = vm.const.i32.zero : i32
    %c2 = vm.const.i32 2 : i32
    %c4 = vm.const.i32 4 : i32
    %c1 = vm.const.i32 1 : i32
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %c50 = vm.const.i32 50 : i32
    %c14 = vm.const.i32 14 : i32
    %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
    %c1_2 = vm.const.i32 1 : i32
    %c3 = vm.const.i32 3 : i32
    %ref_3 = vm.call @hal.command_buffer.create(%ref, %c1_2, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.call @hal.command_buffer.begin(%ref_3) : (!vm.ref<!hal.command_buffer>) -> ()
    %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_3, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
    %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
    vm.cond_br %_device_match_id_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
    %zero_4 = vm.const.i32.zero : i32
    vm.call @hal.command_buffer.dispatch(%ref_3, %_executable_dot_dispatch_0, %zero_4, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    %c20 = vm.const.i32 20 : i32
    %c5 = vm.const.i32 5 : i32
    %zero_5 = vm.const.i32.zero : i32
    vm.call @hal.command_buffer.execution_barrier(%ref_3, %c20, %c5, %zero_5) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.end(%ref_3) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.call @hal.ex.submit_and_wait(%ref, %ref_3) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref_1 : !vm.ref<!hal.buffer>
  ^bb2:  // pred: ^bb0
    %c2_6 = vm.const.i32 2 : i32
    vm.fail %c2_6, "device not supported in the compiled configuration"
  }
  vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
    %c32 = vm.const.i32 32 : i32
    %c64 = vm.const.i32 64 : i32
    %c50331680 = vm.const.i32 50331680 : i32
    %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
    vm.cond_fail %0, "semaphore wait failed"
    %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
    vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
    vm.return %ref_2 : !vm.ref<!hal.buffer_view>
  }
  vm.export @dot$async
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.wrap.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.ref<!iree.byte_buffer>, %offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.allocator(%buffer : !vm.ref<!hal.buffer>) -> !vm.ref<!hal.allocator> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.byte_length(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.trace(%key : !vm.ref<!iree.byte_buffer>, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32, %pattern : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.bind_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %descriptor_set : !vm.ref<!hal.descriptor_set>, %dynamic_offsets : i32 ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set.create(%device : !vm.ref<!hal.device>, %set_layout : !vm.ref<!hal.descriptor_set_layout>, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) -> !vm.ref<!hal.descriptor_set> attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i32(%device : !vm.ref<!hal.device>, %key : !vm.ref<!iree.byte_buffer>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.semaphore.query(%semaphore : !vm.ref<!hal.semaphore>) -> (i32, i32) attributes {sym_visibility = "private"}
  vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
  vm.import @hal.semaphore.fail(%semaphore : !vm.ref<!hal.semaphore>, %status : i32) attributes {sym_visibility = "private"}
  vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
  vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %zero = vm.const.i32.zero : i32
    %c1 = vm.const.i32 1 : i32
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
    %ref_1 = vm.call @dot$async(%ref_0, %zero, %arg0, %arg1, %ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.semaphore>, i32) -> !vm.ref<!hal.buffer_view>
    %0 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
    vm.cond_fail %0, "semaphore wait failed"
    vm.return %ref_1 : !vm.ref<!hal.buffer_view>
  }
  vm.export @dot$sync as("dot")
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass

{% raw %}
```
vm.module @module {
  vm.global.i32 @_device_match_id_0 mutable : i32
  vm.rodata @_utf8_vulkan_7197BF52A22CAFD7 dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
  vm.func private @_device_match_id_0_initializer() -> i32 {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
    %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
    vm.return %0 : i32
  }
  vm.global.ref @_descriptor_set_layout_0 mutable : !vm.ref<!hal.descriptor_set_layout>
  vm.func private @_descriptor_set_layout_0_initializer() -> !vm.ref<!hal.descriptor_set_layout> {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %c1 = vm.const.i32 1 : i32
    %zero = vm.const.i32.zero : i32
    %c7 = vm.const.i32 7 : i32
    %c1_0 = vm.const.i32 1 : i32
    %c1_1 = vm.const.i32 1 : i32
    %c7_2 = vm.const.i32 7 : i32
    %c1_3 = vm.const.i32 1 : i32
    %c2 = vm.const.i32 2 : i32
    %c7_4 = vm.const.i32 7 : i32
    %c6 = vm.const.i32 6 : i32
    %ref_5 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %c1, [(%zero, %c7, %c1_0), (%c1_1, %c7_2, %c1_3), (%c2, %c7_4, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    vm.return %ref_5 : !vm.ref<!hal.descriptor_set_layout>
  }
  vm.global.ref @_executable_layout_0 mutable : !vm.ref<!hal.executable_layout>
  vm.func private @_executable_layout_0_initializer() -> !vm.ref<!hal.executable_layout> {
    %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %zero = vm.const.i32.zero : i32
    %ref_0 = vm.call.variadic @hal.executable_layout.create(%ref, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
    vm.return %ref_0 : !vm.ref<!hal.executable_layout>
  }
  vm.global.ref @_executable_dot_dispatch_0 mutable : !vm.ref<!hal.executable>
  vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
  vm.rodata @_utf8_spve_9EB892746B9D70D0 dense<[83, 80, 86, 69]> : vector<4xi8>
  vm.func private @_executable_dot_dispatch_0_initializer() -> !vm.ref<!hal.executable> {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
    vm.cond_br %_device_match_id_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
    %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
    %ref_0 = vm.call.variadic @hal.executable.create(%ref, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_0 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%0: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.return %0 : !vm.ref<!hal.executable>
  }
  vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
    %c131072 = vm.const.i32 131072 : i32
    %c262144 = vm.const.i32 262144 : i32
    %c8192 = vm.const.i32 8192 : i32
    %zero = vm.const.i32.zero : i32
    %c2 = vm.const.i32 2 : i32
    %c4 = vm.const.i32 4 : i32
    %c1 = vm.const.i32 1 : i32
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %c50 = vm.const.i32 50 : i32
    %c14 = vm.const.i32 14 : i32
    %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
    %c1_2 = vm.const.i32 1 : i32
    %c3 = vm.const.i32 3 : i32
    %ref_3 = vm.call @hal.command_buffer.create(%ref, %c1_2, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.call @hal.command_buffer.begin(%ref_3) : (!vm.ref<!hal.command_buffer>) -> ()
    %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_3, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
    %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
    vm.cond_br %_device_match_id_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
    %zero_4 = vm.const.i32.zero : i32
    vm.call @hal.command_buffer.dispatch(%ref_3, %_executable_dot_dispatch_0, %zero_4, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    %c20 = vm.const.i32 20 : i32
    %c5 = vm.const.i32 5 : i32
    %zero_5 = vm.const.i32.zero : i32
    vm.call @hal.command_buffer.execution_barrier(%ref_3, %c20, %c5, %zero_5) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.end(%ref_3) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.call @hal.ex.submit_and_wait(%ref, %ref_3) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref_1 : !vm.ref<!hal.buffer>
  ^bb2:  // pred: ^bb0
    %c2_6 = vm.const.i32 2 : i32
    vm.fail %c2_6, "device not supported in the compiled configuration"
  }
  vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
    %c32 = vm.const.i32 32 : i32
    %c64 = vm.const.i32 64 : i32
    %c50331680 = vm.const.i32 50331680 : i32
    %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
    vm.cond_fail %0, "semaphore wait failed"
    %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
    vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
    vm.return %ref_2 : !vm.ref<!hal.buffer_view>
  }
  vm.export @dot$async
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.wrap.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.ref<!iree.byte_buffer>, %offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.allocator(%buffer : !vm.ref<!hal.buffer>) -> !vm.ref<!hal.allocator> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.byte_length(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.trace(%key : !vm.ref<!iree.byte_buffer>, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32, %pattern : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.bind_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %descriptor_set : !vm.ref<!hal.descriptor_set>, %dynamic_offsets : i32 ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set.create(%device : !vm.ref<!hal.device>, %set_layout : !vm.ref<!hal.descriptor_set_layout>, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) -> !vm.ref<!hal.descriptor_set> attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i32(%device : !vm.ref<!hal.device>, %key : !vm.ref<!iree.byte_buffer>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.semaphore.query(%semaphore : !vm.ref<!hal.semaphore>) -> (i32, i32) attributes {sym_visibility = "private"}
  vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
  vm.import @hal.semaphore.fail(%semaphore : !vm.ref<!hal.semaphore>, %status : i32) attributes {sym_visibility = "private"}
  vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
  vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %zero = vm.const.i32.zero : i32
    %c1 = vm.const.i32 1 : i32
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
    %ref_1 = vm.call @dot$async(%ref_0, %zero, %arg0, %arg1, %ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.semaphore>, i32) -> !vm.ref<!hal.buffer_view>
    %0 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
    vm.cond_fail %0, "semaphore wait failed"
    vm.return %ref_1 : !vm.ref<!hal.buffer_view>
  }
  vm.export @dot$sync as("dot")
  vm.func @__init() {
    %0 = vm.call @_device_match_id_0_initializer() : () -> i32
    vm.global.store.i32 %0, @_device_match_id_0 : i32
    %ref = vm.call @_descriptor_set_layout_0_initializer() : () -> !vm.ref<!hal.descriptor_set_layout>
    vm.global.store.ref %ref, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
    %ref_0 = vm.call @_executable_layout_0_initializer() : () -> !vm.ref<!hal.executable_layout>
    vm.global.store.ref %ref_0, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    %ref_1 = vm.call @_executable_dot_dispatch_0_initializer() : () -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.export @__init
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @__init() {
  %0 = vm.call @_device_match_id_0_initializer() : () -> i32
  vm.global.store.i32 %0, @_device_match_id_0 : i32
  %ref = vm.call @_descriptor_set_layout_0_initializer() : () -> !vm.ref<!hal.descriptor_set_layout>
  vm.global.store.ref %ref, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
  %ref_0 = vm.call @_executable_layout_0_initializer() : () -> !vm.ref<!hal.executable_layout>
  vm.global.store.ref %ref_0, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
  %ref_1 = vm.call @_executable_dot_dispatch_0_initializer() : () -> !vm.ref<!hal.executable>
  vm.global.store.ref %ref_1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %zero = vm.const.i32.zero : i32
  %c1 = vm.const.i32 1 : i32
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
  %ref_1 = vm.call @dot$async(%ref_0, %zero, %arg0, %arg1, %ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.buffer_view>, !vm.ref<!hal.semaphore>, i32) -> !vm.ref<!hal.buffer_view>
  %0 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
  vm.cond_br %0, ^bb2(%0 : i32), ^bb1
^bb1:  // pred: ^bb0
  vm.return %ref_1 : !vm.ref<!hal.buffer_view>
^bb2(%1: i32):  // pred: ^bb0
  vm.fail %1, "semaphore wait failed"
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
  %c32 = vm.const.i32 32 : i32
  %c64 = vm.const.i32 64 : i32
  %c50331680 = vm.const.i32 50331680 : i32
  %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
  vm.cond_br %0, ^bb2(%0 : i32), ^bb1
^bb1:  // pred: ^bb0
  %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
  %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
  vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
  vm.return %ref_2 : !vm.ref<!hal.buffer_view>
^bb2(%1: i32):  // pred: ^bb0
  vm.fail %1, "semaphore wait failed"
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
  %c131072 = vm.const.i32 131072 : i32
  %c262144 = vm.const.i32 262144 : i32
  %c8192 = vm.const.i32 8192 : i32
  %c4 = vm.const.i32 4 : i32
  %c50 = vm.const.i32 50 : i32
  %c14 = vm.const.i32 14 : i32
  %c1 = vm.const.i32 1 : i32
  %c3 = vm.const.i32 3 : i32
  %c20 = vm.const.i32 20 : i32
  %c5 = vm.const.i32 5 : i32
  %zero = vm.const.i32.zero : i32
  %c2 = vm.const.i32 2 : i32
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
  %ref_2 = vm.call @hal.command_buffer.create(%ref, %c1, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
  vm.call @hal.command_buffer.begin(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
  %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_2, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
  %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
  vm.cond_br %_device_match_id_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
  vm.call @hal.command_buffer.dispatch(%ref_2, %_executable_dot_dispatch_0, %zero, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.execution_barrier(%ref_2, %c20, %c5, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.end(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
  vm.call @hal.ex.submit_and_wait(%ref, %ref_2) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
  vm.return %ref_1 : !vm.ref<!hal.buffer>
^bb2:  // pred: ^bb0
  vm.fail %c2, "device not supported in the compiled configuration"
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func private @_executable_dot_dispatch_0_initializer() -> !vm.ref<!hal.executable> {
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
  vm.cond_br %_device_match_id_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
  %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
  %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
  %ref_0 = vm.call.variadic @hal.executable.create(%ref, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_0 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%0: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.return %0 : !vm.ref<!hal.executable>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func private @_executable_layout_0_initializer() -> !vm.ref<!hal.executable_layout> {
  %zero = vm.const.i32.zero : i32
  %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_0 = vm.call.variadic @hal.executable_layout.create(%ref, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
  vm.return %ref_0 : !vm.ref<!hal.executable_layout>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func private @_descriptor_set_layout_0_initializer() -> !vm.ref<!hal.descriptor_set_layout> {
  %zero = vm.const.i32.zero : i32
  %c1 = vm.const.i32 1 : i32
  %c2 = vm.const.i32 2 : i32
  %c7 = vm.const.i32 7 : i32
  %c6 = vm.const.i32 6 : i32
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_0 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %c1, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  vm.return %ref_0 : !vm.ref<!hal.descriptor_set_layout>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func private @_device_match_id_0_initializer() -> i32 {
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
  %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
  vm.return %0 : i32
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @__init() {
  %c1 = vm.const.i32 1 : i32
  %c2 = vm.const.i32 2 : i32
  %c7 = vm.const.i32 7 : i32
  %c6 = vm.const.i32 6 : i32
  %zero = vm.const.i32.zero : i32
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
  %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
  vm.global.store.i32 %0, @_device_match_id_0 : i32
  %ref_0 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref_0, %c1, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  vm.global.store.ref %ref_1, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
  %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
  %ref_2 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_3 = vm.call.variadic @hal.executable_layout.create(%ref_2, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
  vm.global.store.ref %ref_3, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
  %ref_4 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
  vm.cond_br %_device_match_id_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
  %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
  %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
  %ref_5 = vm.call.variadic @hal.executable.create(%ref_4, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%1: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.global.store.ref %1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
  %zero = vm.const.i32.zero : i32
  %c1 = vm.const.i32 1 : i32
  %c32 = vm.const.i32 32 : i32
  %c64 = vm.const.i32 64 : i32
  %c50331680 = vm.const.i32 50331680 : i32
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
  %0 = vm.call @hal.semaphore.await(%ref_0, %zero) : (!vm.ref<!hal.semaphore>, i32) -> i32
  vm.cond_br %0, ^bb2(%0 : i32), ^bb1
^bb1:  // pred: ^bb0
  %ref_1 = vm.call @hal.buffer_view.buffer(%arg0) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_2 = vm.call @hal.buffer_view.buffer(%arg1) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_3 = vm.call @dot(%ref_1, %ref_2) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call.variadic @hal.buffer_view.create(%ref_3, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
  vm.call @hal.semaphore.signal(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> ()
  %1 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
  vm.cond_br %1, ^bb2(%1 : i32), ^bb3
^bb2(%2: i32):  // 2 preds: ^bb0, ^bb1
  vm.fail %2, "semaphore wait failed"
^bb3:  // pred: ^bb1
  vm.return %ref_4 : !vm.ref<!hal.buffer_view>
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
  %c32 = vm.const.i32 32 : i32
  %c64 = vm.const.i32 64 : i32
  %c50331680 = vm.const.i32 50331680 : i32
  %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
  vm.cond_br %0, ^bb2(%0 : i32), ^bb1
^bb1:  // pred: ^bb0
  %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
  %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
  vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
  vm.return %ref_2 : !vm.ref<!hal.buffer_view>
^bb2(%1: i32):  // pred: ^bb0
  vm.fail %1, "semaphore wait failed"
}

```
{% endraw %}

### IR Dump After Canonicalizer

{% raw %}
```
vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
  %c131072 = vm.const.i32 131072 : i32
  %c262144 = vm.const.i32 262144 : i32
  %c8192 = vm.const.i32 8192 : i32
  %c4 = vm.const.i32 4 : i32
  %c50 = vm.const.i32 50 : i32
  %c14 = vm.const.i32 14 : i32
  %c1 = vm.const.i32 1 : i32
  %c3 = vm.const.i32 3 : i32
  %c20 = vm.const.i32 20 : i32
  %c5 = vm.const.i32 5 : i32
  %zero = vm.const.i32.zero : i32
  %c2 = vm.const.i32 2 : i32
  %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
  %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
  %ref_2 = vm.call @hal.command_buffer.create(%ref, %c1, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
  vm.call @hal.command_buffer.begin(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
  %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_2, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
  %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
  vm.cond_br %_device_match_id_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
  vm.call @hal.command_buffer.dispatch(%ref_2, %_executable_dot_dispatch_0, %zero, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.execution_barrier(%ref_2, %c20, %c5, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.end(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
  vm.call @hal.ex.submit_and_wait(%ref, %ref_2) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
  vm.return %ref_1 : !vm.ref<!hal.buffer>
^bb2:  // pred: ^bb0
  vm.fail %c2, "device not supported in the compiled configuration"
}

```
{% endraw %}

### IR Dump After Inliner

{% raw %}
```
module  {
  vm.module @module {
    vm.global.i32 @_device_match_id_0 mutable : i32
    vm.rodata @_utf8_vulkan_7197BF52A22CAFD7 dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
    vm.global.ref @_descriptor_set_layout_0 mutable : !vm.ref<!hal.descriptor_set_layout>
    vm.global.ref @_executable_layout_0 mutable : !vm.ref<!hal.executable_layout>
    vm.global.ref @_executable_dot_dispatch_0 mutable : !vm.ref<!hal.executable>
    vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
    vm.rodata @_utf8_spve_9EB892746B9D70D0 dense<[83, 80, 86, 69]> : vector<4xi8>
    vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
      %c131072 = vm.const.i32 131072 : i32
      %c262144 = vm.const.i32 262144 : i32
      %c8192 = vm.const.i32 8192 : i32
      %c4 = vm.const.i32 4 : i32
      %c50 = vm.const.i32 50 : i32
      %c14 = vm.const.i32 14 : i32
      %c1 = vm.const.i32 1 : i32
      %c3 = vm.const.i32 3 : i32
      %c20 = vm.const.i32 20 : i32
      %c5 = vm.const.i32 5 : i32
      %zero = vm.const.i32.zero : i32
      %c2 = vm.const.i32 2 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.command_buffer.create(%ref, %c1, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.call @hal.command_buffer.begin(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_2, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      vm.call @hal.command_buffer.dispatch(%ref_2, %_executable_dot_dispatch_0, %zero, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_2, %c20, %c5, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.end(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.call @hal.ex.submit_and_wait(%ref, %ref_2) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref_1 : !vm.ref<!hal.buffer>
    ^bb2:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
      vm.return %ref_2 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "semaphore wait failed"
    }
    vm.export @dot$async
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.wrap.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.ref<!iree.byte_buffer>, %offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.allocator(%buffer : !vm.ref<!hal.buffer>) -> !vm.ref<!hal.allocator> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.byte_length(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.ref<!iree.byte_buffer>, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32, %pattern : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.bind_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %descriptor_set : !vm.ref<!hal.descriptor_set>, %dynamic_offsets : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set.create(%device : !vm.ref<!hal.device>, %set_layout : !vm.ref<!hal.descriptor_set_layout>, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) -> !vm.ref<!hal.descriptor_set> attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i32(%device : !vm.ref<!hal.device>, %key : !vm.ref<!iree.byte_buffer>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.query(%semaphore : !vm.ref<!hal.semaphore>) -> (i32, i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.fail(%semaphore : !vm.ref<!hal.semaphore>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
    vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
      %zero = vm.const.i32.zero : i32
      %c1 = vm.const.i32 1 : i32
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
      %0 = vm.call @hal.semaphore.await(%ref_0, %zero) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_1 = vm.call @hal.buffer_view.buffer(%arg0) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.buffer_view.buffer(%arg1) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_3 = vm.call @dot(%ref_1, %ref_2) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call.variadic @hal.buffer_view.create(%ref_3, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> ()
      %1 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %1, ^bb2(%1 : i32), ^bb3
    ^bb2(%2: i32):  // 2 preds: ^bb0, ^bb1
      vm.fail %2, "semaphore wait failed"
    ^bb3:  // pred: ^bb1
      vm.return %ref_4 : !vm.ref<!hal.buffer_view>
    }
    vm.export @dot$sync as("dot")
    vm.func @__init() {
      %c1 = vm.const.i32 1 : i32
      %c2 = vm.const.i32 2 : i32
      %c7 = vm.const.i32 7 : i32
      %c6 = vm.const.i32 6 : i32
      %zero = vm.const.i32.zero : i32
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
      %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
      vm.global.store.i32 %0, @_device_match_id_0 : i32
      %ref_0 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref_0, %c1, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      vm.global.store.ref %ref_1, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call.variadic @hal.executable_layout.create(%ref_2, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
      vm.global.store.ref %ref_3, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %ref_4 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
      %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
      %ref_5 = vm.call.variadic @hal.executable.create(%ref_4, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%1: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__init
  }
}

```
{% endraw %}

### IR Dump After CSE

{% raw %}
```
module  {
  vm.module @module {
    vm.global.i32 @_device_match_id_0 mutable : i32
    vm.rodata @_utf8_vulkan_7197BF52A22CAFD7 dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
    vm.global.ref @_descriptor_set_layout_0 mutable : !vm.ref<!hal.descriptor_set_layout>
    vm.global.ref @_executable_layout_0 mutable : !vm.ref<!hal.executable_layout>
    vm.global.ref @_executable_dot_dispatch_0 mutable : !vm.ref<!hal.executable>
    vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
    vm.rodata @_utf8_spve_9EB892746B9D70D0 dense<[83, 80, 86, 69]> : vector<4xi8>
    vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
      %c131072 = vm.const.i32 131072 : i32
      %c262144 = vm.const.i32 262144 : i32
      %c8192 = vm.const.i32 8192 : i32
      %c4 = vm.const.i32 4 : i32
      %c50 = vm.const.i32 50 : i32
      %c14 = vm.const.i32 14 : i32
      %c1 = vm.const.i32 1 : i32
      %c3 = vm.const.i32 3 : i32
      %c20 = vm.const.i32 20 : i32
      %c5 = vm.const.i32 5 : i32
      %zero = vm.const.i32.zero : i32
      %c2 = vm.const.i32 2 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.command_buffer.create(%ref, %c1, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.call @hal.command_buffer.begin(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_2, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      vm.call @hal.command_buffer.dispatch(%ref_2, %_executable_dot_dispatch_0, %zero, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_2, %c20, %c5, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.end(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.call @hal.ex.submit_and_wait(%ref, %ref_2) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref_1 : !vm.ref<!hal.buffer>
    ^bb2:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
      vm.return %ref_2 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "semaphore wait failed"
    }
    vm.export @dot$async
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.wrap.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.ref<!iree.byte_buffer>, %offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.allocator(%buffer : !vm.ref<!hal.buffer>) -> !vm.ref<!hal.allocator> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.byte_length(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.ref<!iree.byte_buffer>, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32, %pattern : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i32, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.bind_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %descriptor_set : !vm.ref<!hal.descriptor_set>, %dynamic_offsets : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set.create(%device : !vm.ref<!hal.device>, %set_layout : !vm.ref<!hal.descriptor_set_layout>, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) -> !vm.ref<!hal.descriptor_set> attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i32(%device : !vm.ref<!hal.device>, %key : !vm.ref<!iree.byte_buffer>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.query(%semaphore : !vm.ref<!hal.semaphore>) -> (i32, i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.fail(%semaphore : !vm.ref<!hal.semaphore>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
    vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
      %zero = vm.const.i32.zero : i32
      %c1 = vm.const.i32 1 : i32
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
      %0 = vm.call @hal.semaphore.await(%ref_0, %zero) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_1 = vm.call @hal.buffer_view.buffer(%arg0) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.buffer_view.buffer(%arg1) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_3 = vm.call @dot(%ref_1, %ref_2) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call.variadic @hal.buffer_view.create(%ref_3, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> ()
      %1 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %1, ^bb2(%1 : i32), ^bb3
    ^bb2(%2: i32):  // 2 preds: ^bb0, ^bb1
      vm.fail %2, "semaphore wait failed"
    ^bb3:  // pred: ^bb1
      vm.return %ref_4 : !vm.ref<!hal.buffer_view>
    }
    vm.export @dot$sync as("dot")
    vm.func @__init() {
      %c1 = vm.const.i32 1 : i32
      %c2 = vm.const.i32 2 : i32
      %c7 = vm.const.i32 7 : i32
      %c6 = vm.const.i32 6 : i32
      %zero = vm.const.i32.zero : i32
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
      %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
      vm.global.store.i32 %0, @_device_match_id_0 : i32
      %ref_0 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref_0, %c1, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      vm.global.store.ref %ref_1, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call.variadic @hal.executable_layout.create(%ref_2, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
      vm.global.store.ref %ref_3, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %ref_4 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
      %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
      %ref_5 = vm.call.variadic @hal.executable.create(%ref_4, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%1: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__init
  }
}

```
{% endraw %}

### IR Dump After SymbolDCE

{% raw %}
```
module  {
  vm.module @module {
    vm.global.i32 @_device_match_id_0 mutable : i32
    vm.rodata @_utf8_vulkan_7197BF52A22CAFD7 dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
    vm.global.ref @_descriptor_set_layout_0 mutable : !vm.ref<!hal.descriptor_set_layout>
    vm.global.ref @_executable_layout_0 mutable : !vm.ref<!hal.executable_layout>
    vm.global.ref @_executable_dot_dispatch_0 mutable : !vm.ref<!hal.executable>
    vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
    vm.rodata @_utf8_spve_9EB892746B9D70D0 dense<[83, 80, 86, 69]> : vector<4xi8>
    vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
      %c131072 = vm.const.i32 131072 : i32
      %c262144 = vm.const.i32 262144 : i32
      %c8192 = vm.const.i32 8192 : i32
      %c4 = vm.const.i32 4 : i32
      %c50 = vm.const.i32 50 : i32
      %c14 = vm.const.i32 14 : i32
      %c1 = vm.const.i32 1 : i32
      %c3 = vm.const.i32 3 : i32
      %c20 = vm.const.i32 20 : i32
      %c5 = vm.const.i32 5 : i32
      %zero = vm.const.i32.zero : i32
      %c2 = vm.const.i32 2 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.command_buffer.create(%ref, %c1, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.call @hal.command_buffer.begin(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_2, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      vm.call @hal.command_buffer.dispatch(%ref_2, %_executable_dot_dispatch_0, %zero, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_2, %c20, %c5, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.end(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.call @hal.ex.submit_and_wait(%ref, %ref_2) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref_1 : !vm.ref<!hal.buffer>
    ^bb2:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
      vm.return %ref_2 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "semaphore wait failed"
    }
    vm.export @dot$async
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
    vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
      %zero = vm.const.i32.zero : i32
      %c1 = vm.const.i32 1 : i32
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
      %0 = vm.call @hal.semaphore.await(%ref_0, %zero) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_1 = vm.call @hal.buffer_view.buffer(%arg0) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.buffer_view.buffer(%arg1) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_3 = vm.call @dot(%ref_1, %ref_2) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call.variadic @hal.buffer_view.create(%ref_3, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> ()
      %1 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %1, ^bb2(%1 : i32), ^bb3
    ^bb2(%2: i32):  // 2 preds: ^bb0, ^bb1
      vm.fail %2, "semaphore wait failed"
    ^bb3:  // pred: ^bb1
      vm.return %ref_4 : !vm.ref<!hal.buffer_view>
    }
    vm.export @dot$sync as("dot")
    vm.func @__init() {
      %c1 = vm.const.i32 1 : i32
      %c2 = vm.const.i32 2 : i32
      %c7 = vm.const.i32 7 : i32
      %c6 = vm.const.i32 6 : i32
      %zero = vm.const.i32.zero : i32
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
      %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
      vm.global.store.i32 %0, @_device_match_id_0 : i32
      %ref_0 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref_0, %c1, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      vm.global.store.ref %ref_1, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call.variadic @hal.executable_layout.create(%ref_2, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
      vm.global.store.ref %ref_3, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %ref_4 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
      %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
      %ref_5 = vm.call.variadic @hal.executable.create(%ref_4, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%1: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__init
  }
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::VM::SinkDefiningOpsPass

{% raw %}
```
vm.module @module {
  vm.global.i32 @_device_match_id_0 mutable : i32
  vm.rodata @_utf8_vulkan_7197BF52A22CAFD7 dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
  vm.global.ref @_descriptor_set_layout_0 mutable : !vm.ref<!hal.descriptor_set_layout>
  vm.global.ref @_executable_layout_0 mutable : !vm.ref<!hal.executable_layout>
  vm.global.ref @_executable_dot_dispatch_0 mutable : !vm.ref<!hal.executable>
  vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
  vm.rodata @_utf8_spve_9EB892746B9D70D0 dense<[83, 80, 86, 69]> : vector<4xi8>
  vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %c8192 = vm.const.i32 8192 : i32
    %c50 = vm.const.i32 50 : i32
    %c14 = vm.const.i32 14 : i32
    %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1 : i32
    %c3 = vm.const.i32 3 : i32
    %ref_2 = vm.call @hal.command_buffer.create(%ref, %c1, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.call @hal.command_buffer.begin(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
    %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    %c131072 = vm.const.i32 131072 : i32
    %c262144 = vm.const.i32 262144 : i32
    %zero = vm.const.i32.zero : i32
    %c2 = vm.const.i32 2 : i32
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_2, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
    %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
    vm.cond_br %_device_match_id_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
    %c4 = vm.const.i32 4 : i32
    vm.call @hal.command_buffer.dispatch(%ref_2, %_executable_dot_dispatch_0, %zero, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    %c20 = vm.const.i32 20 : i32
    %c5 = vm.const.i32 5 : i32
    vm.call @hal.command_buffer.execution_barrier(%ref_2, %c20, %c5, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.end(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.call @hal.ex.submit_and_wait(%ref, %ref_2) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref_1 : !vm.ref<!hal.buffer>
  ^bb2:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
    %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
    vm.cond_br %0, ^bb2(%0 : i32), ^bb1
  ^bb1:  // pred: ^bb0
    %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
    %c32 = vm.const.i32 32 : i32
    %c64 = vm.const.i32 64 : i32
    %c50331680 = vm.const.i32 50331680 : i32
    %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
    vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
    vm.return %ref_2 : !vm.ref<!hal.buffer_view>
  ^bb2(%1: i32):  // pred: ^bb0
    vm.fail %1, "semaphore wait failed"
  }
  vm.export @dot$async
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
  vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
  vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %zero = vm.const.i32.zero : i32
    %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
    %0 = vm.call @hal.semaphore.await(%ref_0, %zero) : (!vm.ref<!hal.semaphore>, i32) -> i32
    vm.cond_br %0, ^bb2(%0 : i32), ^bb1
  ^bb1:  // pred: ^bb0
    %ref_1 = vm.call @hal.buffer_view.buffer(%arg0) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.buffer_view.buffer(%arg1) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_3 = vm.call @dot(%ref_1, %ref_2) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
    %c32 = vm.const.i32 32 : i32
    %c64 = vm.const.i32 64 : i32
    %c50331680 = vm.const.i32 50331680 : i32
    %ref_4 = vm.call.variadic @hal.buffer_view.create(%ref_3, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
    %c1 = vm.const.i32 1 : i32
    vm.call @hal.semaphore.signal(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> ()
    %1 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
    vm.cond_br %1, ^bb2(%1 : i32), ^bb3
  ^bb2(%2: i32):  // 2 preds: ^bb0, ^bb1
    vm.fail %2, "semaphore wait failed"
  ^bb3:  // pred: ^bb1
    vm.return %ref_4 : !vm.ref<!hal.buffer_view>
  }
  vm.export @dot$sync as("dot")
  vm.func @__init() {
    %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
    %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
    vm.global.store.i32 %0, @_device_match_id_0 : i32
    %ref_0 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %c1 = vm.const.i32 1 : i32
    %c2 = vm.const.i32 2 : i32
    %c7 = vm.const.i32 7 : i32
    %c6 = vm.const.i32 6 : i32
    %zero = vm.const.i32.zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref_0, %c1, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    vm.global.store.ref %ref_1, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
    %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call.variadic @hal.executable_layout.create(%ref_2, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
    vm.global.store.ref %ref_3, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    %ref_4 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
    %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
    vm.cond_br %_device_match_id_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
    %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
    %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
    %ref_5 = vm.call.variadic @hal.executable.create(%ref_4, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%1: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.export @__init
}

```
{% endraw %}

### IR Dump After mlir::iree_compiler::IREE::DropCompilerHintsPass

{% raw %}
```
module  {
  vm.module @module {
    vm.global.i32 @_device_match_id_0 mutable : i32
    vm.rodata @_utf8_vulkan_7197BF52A22CAFD7 dense<[118, 117, 108, 107, 97, 110, 42]> : vector<7xi8>
    vm.global.ref @_descriptor_set_layout_0 mutable : !vm.ref<!hal.descriptor_set_layout>
    vm.global.ref @_executable_layout_0 mutable : !vm.ref<!hal.executable_layout>
    vm.global.ref @_executable_dot_dispatch_0 mutable : !vm.ref<!hal.executable>
    vm.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve opaque<"_", "0xDEADBEEF"> : vector<2332xi8>
    vm.rodata @_utf8_spve_9EB892746B9D70D0 dense<[83, 80, 86, 69]> : vector<4xi8>
    vm.func @dot(%arg0: !vm.ref<!hal.buffer>, %arg1: !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer> attributes {noinline} {
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_0 = vm.call @hal.device.allocator(%ref) : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %c8192 = vm.const.i32 8192 : i32
      %c50 = vm.const.i32 50 : i32
      %c14 = vm.const.i32 14 : i32
      %ref_1 = vm.call @hal.allocator.allocate(%ref_0, %c50, %c14, %c8192) : (!vm.ref<!hal.allocator>, i32, i32, i32) -> !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1 : i32
      %c3 = vm.const.i32 3 : i32
      %ref_2 = vm.call @hal.command_buffer.create(%ref, %c1, %c3) : (!vm.ref<!hal.device>, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.call @hal.command_buffer.begin(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %c131072 = vm.const.i32 131072 : i32
      %c262144 = vm.const.i32 262144 : i32
      %zero = vm.const.i32.zero : i32
      %c2 = vm.const.i32 2 : i32
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_2, %_executable_layout_0, %zero, [(%zero, %arg0, %zero, %c131072), (%c1, %arg1, %zero, %c262144), (%c2, %ref_1, %zero, %c8192)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable_layout>, i32, tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...)
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_dot_dispatch_0 = vm.global.load.ref @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      %c4 = vm.const.i32 4 : i32
      vm.call @hal.command_buffer.dispatch(%ref_2, %_executable_dot_dispatch_0, %zero, %c4, %c4, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      %c20 = vm.const.i32 20 : i32
      %c5 = vm.const.i32 5 : i32
      vm.call @hal.command_buffer.execution_barrier(%ref_2, %c20, %c5, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.end(%ref_2) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.call @hal.ex.submit_and_wait(%ref, %ref_2) : (!vm.ref<!hal.device>, !vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref_1 : !vm.ref<!hal.buffer>
    ^bb2:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.func @dot$async(%arg0: !vm.ref<!hal.semaphore>, %arg1: i32, %arg2: !vm.ref<!hal.buffer_view>, %arg3: !vm.ref<!hal.buffer_view>, %arg4: !vm.ref<!hal.semaphore>, %arg5: i32) -> !vm.ref<!hal.buffer_view> {
      %0 = vm.call @hal.semaphore.await(%arg0, %arg1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref = vm.call @hal.buffer_view.buffer(%arg2) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_0 = vm.call @hal.buffer_view.buffer(%arg3) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @dot(%ref, %ref_0) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %ref_2 = vm.call.variadic @hal.buffer_view.create(%ref_1, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      vm.call @hal.semaphore.signal(%arg4, %arg5) : (!vm.ref<!hal.semaphore>, i32) -> ()
      vm.return %ref_2 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "semaphore wait failed"
    }
    vm.export @dot$async
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i32) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %element_type : i32, %shape : i32 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %executable_layout : !vm.ref<!hal.executable_layout>, %set : i32, %bindings : tuple<i32, !vm.ref<!hal.buffer>, i32, i32> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %usage_type : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.match.id(%device : !vm.ref<!hal.device>, %pattern : !vm.ref<!iree.byte_buffer>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.ref<!iree.byte_buffer>, %executable_data : !vm.ref<!iree.byte_buffer>, %executable_layouts : !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.executable_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.create(%device : !vm.ref<!hal.device>, %initial_value : i32) -> !vm.ref<!hal.semaphore> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.semaphore.signal(%semaphore : !vm.ref<!hal.semaphore>, %new_value : i32) attributes {sym_visibility = "private"}
    vm.import @hal.semaphore.await(%semaphore : !vm.ref<!hal.semaphore>, %min_value : i32) -> i32 attributes {sym_visibility = "private"}
    vm.func @dot$sync(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {f = "I23!B9!d32d1024B9!d1024d64R10!B7!d32d64", fv = "1"}} {
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %zero = vm.const.i32.zero : i32
      %ref_0 = vm.call @hal.semaphore.create(%ref, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.semaphore>
      %0 = vm.call @hal.semaphore.await(%ref_0, %zero) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_1 = vm.call @hal.buffer_view.buffer(%arg0) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.buffer_view.buffer(%arg1) : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_3 = vm.call @dot(%ref_1, %ref_2) : (!vm.ref<!hal.buffer>, !vm.ref<!hal.buffer>) -> !vm.ref<!hal.buffer>
      %c32 = vm.const.i32 32 : i32
      %c64 = vm.const.i32 64 : i32
      %c50331680 = vm.const.i32 50331680 : i32
      %ref_4 = vm.call.variadic @hal.buffer_view.create(%ref_3, %c50331680, [%c32, %c64]) : (!vm.ref<!hal.buffer>, i32, i32 ...) -> !vm.ref<!hal.buffer_view>
      %c1 = vm.const.i32 1 : i32
      vm.call @hal.semaphore.signal(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> ()
      %1 = vm.call @hal.semaphore.await(%ref_0, %c1) : (!vm.ref<!hal.semaphore>, i32) -> i32
      vm.cond_br %1, ^bb2(%1 : i32), ^bb3
    ^bb2(%2: i32):  // 2 preds: ^bb0, ^bb1
      vm.fail %2, "semaphore wait failed"
    ^bb3:  // pred: ^bb1
      vm.return %ref_4 : !vm.ref<!hal.buffer_view>
    }
    vm.export @dot$sync as("dot")
    vm.func @__init() {
      %ref = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_utf8_vulkan_7197BF52A22CAFD7 = vm.const.ref.rodata @_utf8_vulkan_7197BF52A22CAFD7 : !vm.ref<!iree.byte_buffer>
      %0 = vm.call @hal.device.match.id(%ref, %_utf8_vulkan_7197BF52A22CAFD7) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>) -> i32
      vm.global.store.i32 %0, @_device_match_id_0 : i32
      %ref_0 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %c1 = vm.const.i32 1 : i32
      %c2 = vm.const.i32 2 : i32
      %c7 = vm.const.i32 7 : i32
      %c6 = vm.const.i32 6 : i32
      %zero = vm.const.i32.zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref_0, %c1, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %c6)]) : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      vm.global.store.ref %ref_1, @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %_descriptor_set_layout_0 = vm.global.load.ref @_descriptor_set_layout_0 : !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call.variadic @hal.executable_layout.create(%ref_2, %zero, [%_descriptor_set_layout_0]) : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.executable_layout>
      vm.global.store.ref %ref_3, @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %ref_4 = vm.call @hal.ex.shared_device() : () -> !vm.ref<!hal.device>
      %_device_match_id_0 = vm.global.load.i32 @_device_match_id_0 : i32
      vm.cond_br %_device_match_id_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_executable_layout_0 = vm.global.load.ref @_executable_layout_0 : !vm.ref<!hal.executable_layout>
      %_utf8_spve_9EB892746B9D70D0 = vm.const.ref.rodata @_utf8_spve_9EB892746B9D70D0 : !vm.ref<!iree.byte_buffer>
      %_dot_dispatch_0_vulkan_spirv_binary_spve = vm.const.ref.rodata @_dot_dispatch_0_vulkan_spirv_binary_spve : !vm.ref<!iree.byte_buffer>
      %ref_5 = vm.call.variadic @hal.executable.create(%ref_4, %_utf8_spve_9EB892746B9D70D0, %_dot_dispatch_0_vulkan_spirv_binary_spve, [%_executable_layout_0]) : (!vm.ref<!hal.device>, !vm.ref<!iree.byte_buffer>, !vm.ref<!iree.byte_buffer>, !vm.ref<!hal.executable_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%1: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %1, @_executable_dot_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__init
  }
}

```
{% endraw %}